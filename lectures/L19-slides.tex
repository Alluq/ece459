\input{configuration}

\title{Lecture 19 --- Single Thread Performance}

\author{Patrick Lam \\ \small \texttt{patrick.lam@uwaterloo.ca}}
\institute{Department of Electrical and Computer Engineering \\
  University of Waterloo}
\date{\today}


\begin{document}

\begin{frame}
  \titlepage

\end{frame}

\part{Single-Thread Performance}



\begin{frame}
\frametitle{Single-Thread Performance}

``Can you run faster just by trying harder?''

\begin{center}
\includegraphics[width=0.7\textwidth]{images/theflash.jpg}
\end{center}

\end{frame}


\begin{frame}
\frametitle{Single-Thread Performance}
\Large
\begin{changemargin}{2cm}
Performance improvements to date have \\
used parallelism
to improve throughput. 

Decreasing latency is trickier---\\
often requires domain-specific
tweaks. 

Today: one example of decreasing latency: \\
\hspace*{2em} Stream VByte.
\end{changemargin}

\end{frame}


\begin{frame}
\frametitle{I have a cunning plan...}

\Large
\begin{changemargin}{2cm}
Even Stream VByte uses parallelism:\\
\hspace*{2em}vector instructions. 

But there
are sequential improvements, \\
e.g. Stream VByte takes care to be predictable
for the branch predictor.
\end{changemargin}

\end{frame}
\begin{frame}
\frametitle{Inverted Indexes (like it's CS 137 again!)}

\Large
\begin{changemargin}{1cm}
\vspace*{-1em}
Abstractly: store a sequence of small integers.


Why Inverted indexes?

\hspace*{1cm}allow fast lookups by term;\\
\hspace*{1cm}support boolean queries combining terms.

\end{changemargin}

\end{frame}
\begin{frame}
\frametitle{Dogs, cats, cows, goats. In ur documents.}
\Large
\begin{changemargin}{2cm}
\begin{center}
\begin{tabular}{r|l}
docid & terms \\ \hline
1 & dog, cat, cow\\
2 & cat\\
3 & dog, goat\\
4 & cow, cat, goat\\
\end{tabular}
\end{center}
\end{changemargin}

\end{frame}


\begin{frame}
\frametitle{Inverting the Index}

\large\begin{changemargin}{2cm}
Here's the index and the inverted index:
\begin{center}
\begin{tabular}{r|l}
docid & terms \\ \hline
1 & dog, cat, cow\\
2 & cat\\
3 & dog, goat\\
4 & cow, cat, goat\\
\end{tabular} \hspace*{2em}
\begin{tabular}{r|l}
term & docs \\ \hline
dog & 1, 3 \\
cat & 1, 2, 4 \\
cow & 1, 4 \\
goat & 3, 4
\end{tabular}
\end{center}

Inverted indexes contain many small integers.

Deltas typically small if doc ids are sorted.
\end{changemargin}

\end{frame}


\begin{frame}
\frametitle{Storing inverted index lists: VByte}

\Large\begin{changemargin}{2cm}
\vspace*{-2em}
VByte uses a variable number of bytes\\
to store integers.  

Why? Most integers are
small,\\
especially on today's 64-bit processors.
\end{changemargin}
\end{frame}


\begin{frame}
\frametitle{How VByte Works}

\large\begin{changemargin}{1cm}
VByte works like this:

\begin{itemize}
\item $x$ between 0 and $2^7-1$ (e.g. $17 = 0b10001$):\\
\hspace*{1em}$0xxx xxxx$, e.g. $0001 0001$;
\item $x$ between $2^7$ and $2^{14}-1$ (e.g. $1729 = 0b110 11000001$):\\
\hspace*{1em}                   $1xxx xxxx/0xxx xxxx$ (e.g. $1100 0001/0000 1101$);\\
\item $x$ between $2^{14}$ and $2^{21}-1$: \\
\hspace*{1em}$0xxx xxxx/1xxx xxxx/1xxx xxxx$;
\item etc.
\end{itemize}

Control bit, or high-order bit, is:\\
\hspace*{2em}0 once done representing the int,\\
\hspace*{2em}1 if more bits remain.
\end{changemargin}

\end{frame}



\begin{frame}
\frametitle{Why VByte Helps}

\large\begin{changemargin}{2cm}
Isn't dealing with variable-byte integers harder?\\
\hspace*{2em} $\bullet$~ Yup!

But perf improves: \\
\hspace*{2em} $\bullet$~  We are using fewer bits! 

We fit more information into RAM and
cache, and can get higher throughput. (think inlining)

Storing and reading 0s isn't good use of resources. 

However, a naive algorithm to decode VByte \\
gives branch mispredicts.
\end{changemargin}
\end{frame}

\begin{frame}
\frametitle{Stream VByte}
\vspace*{-2em}
\large\begin{changemargin}{2cm}
Stream VByte: a variant of VByte using SIMD.


Science is incremental. \\
Stream VByte builds on earlier work---\\
\hspace*{2em}masked VByte, {\sc varint}-GB, {\sc varint}-G8IU. 

Innovation in Stream VByte:\\
\hspace*{2em}\emph{store the control and data streams separately}.
\end{changemargin}

\end{frame}

\begin{frame}
\frametitle{Control Stream}
\vspace*{-4em}
\large\begin{changemargin}{2cm}
Stream VByte's control stream uses two bits per integer to represent the size of the integer:
\begin{center}
\vspace*{-3em}
\begin{tabular}{ll@{~~~~~~~~}ll}
00 & 1 byte & 10 & 3 bytes\\
01 & 2 bytes & 11 & 4 bytes
\end{tabular}
\end{center}
\end{changemargin}

\end{frame}


\begin{frame}
\frametitle{Decoding Stream VByte}

\vspace*{-4em}
\large\begin{changemargin}{2cm}
Per decode iteration:\\
\hspace*{2em} reads 1 byte from the control stream,\\
\hspace*{2em} and 16 bytes of data.


Lookup table on control stream byte: decide how many
bytes it needs out of the 16 bytes it has read.

SIMD instructions: \\
\hspace*{2em}shuffle the bits each into their own integers. 

Unlike VByte, \\
Stream VByte uses all 8 bits
of data bytes as data.
\end{changemargin}

\end{frame}



\begin{frame}
\frametitle{Stream VByte Example}

\large\begin{changemargin}{2cm}
Say control stream contains $0b1000~1100$. \\
Then the data stream
contains the following sequence of integer sizes: $3, 1, 4, 1$. 

Out of the 16 bytes read,
this iteration uses 9 bytes; \\
\hspace*{2em} $\Rightarrow$ it advances the data pointer by 9. 

The SIMD
``shuffle'' instruction puts decoded integers from data stream at known positions in the
128-bit SIMD register.

Pad the first 3-byte integer with 1 byte, then
the next 1-byte integer with 3 bytes, etc. 
\end{changemargin}
\end{frame}

\begin{frame}
\frametitle{Stream VByte: Shuffling the Bits}
\vspace*{-1em}
\large\begin{changemargin}{1cm}
Say the data input is:\\
{\tt 0xf823~e127~2524~9748~1b..~....~....~....}. 

The 128-bit output is:\\
{\tt 0x00f8~23e1/0000~0027/2524 9748/0000/001b}\\
/s denote separation
between outputs. 

Shuffle mask is precomputed and
read from an array.
\end{changemargin}
\end{frame}

\begin{frame}[fragile]
\frametitle{SIMD Instructions}

\vspace*{-1em}
\large\begin{changemargin}{1cm}
The core of the implementation uses\\
three SIMD instructions:
\begin{lstlisting}[language=C]
  uint8_t C = lengthTable[control];
  __m128i Data = _mm_loadu_si128 ((__m128i *) databytes);
  __m128i Shuf = _mm_loadu_si128(shuffleTable[control]);
  Data = _mm_shuffle_epi8(Data, Shuf);
  databytes += C; control++;
\end{lstlisting}
\end{changemargin}
\end{frame}


\begin{frame}
\frametitle{But Does It Work?!}

\vspace*{-1em}
\large\begin{changemargin}{1cm}
Stream VByte performs better than previous techniques on a realistic input.


Why?

\begin{itemize}
\item control bytes are sequential:\\
\hspace*{1em} CPU can always prefetch the next control byte, \\
\hspace*{1em} because
its location is predictable;
\item data bytes are sequential \\
\hspace*{1em}and loaded at high throughput;
\item shuffling exploits the instruction set: \\
\hspace*{1em}takes 1 cycle;
\item control-flow is regular \\
\hspace*{1em}(tight loop which retrieves/decodes control
\& data;\\
\hspace*{1em}no conditional jumps).
\end{itemize}
\end{changemargin}
\end{frame}



\end{document}

