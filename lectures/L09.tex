\include{header}

\begin{document}

\lecture{9 --- C++ Atomics, Compiler Hints, Restrict}{\term}{Patrick Lam and Jeff Zarnett}

\section*{C++ Atomics}
We've talked about locks. Atomics are a lower-overhead alternative to
locks as long as you're doing suitable operations. Remember that what we wanted sometimes with locks and mutexes and all that is that operations are indivisible: an update to a variable doesn't get interfered with by another update. Remember the key idea is: an t\textit{atomic operation} is indivisible. Other threads see state before or after the operation; nothing in between.


We are only going to talk about atomics with sequential consistency. If you use the default {\tt std::memory\_order}, that's what you get. What do I mean by that? Well, in the header file \texttt{atomic} (C++11 here) there is an enumeration of memory orders and I am suggesting that using the default is pretty nice, compared to the alternative which may or may not be a Lovecraftian Horror to understand (or prove correctness). If you'd like to know about all the options, take a look at~\cite{cppatomics}, but here's a quick summary from~\cite{bmref1} (which is much more concise than the C++ Atomics listing):

\begin{center}
	\begin{tabular}{l|p{12cm}}
	\textbf{Value} & \textbf{Explanation} \\ \hline
		\texttt{memory\_order\_acquire} &  Subsequent loads are not moved before the current load or any preceding loads.\\ \hline
		\texttt{memory\_order\_release} &  Preceding stores are not moved past the current store or any subsequent stores. \\ \hline
		\texttt{memory\_order\_acq\_rel} & Combine the acquire and release guarantees\\ \hline
		\texttt{memory\_order\_consume} & A potentially weaker form of memory\_order\_acquire that enforces ordering of the current load before other operations that are data-dependent on it (for instance, when a load of a pointer is marked memory\_order\_consume, subsequent operations that dereference this pointer won't be moved before it (yes, even that is not guaranteed on all platforms!).\\ \hline
	
	\texttt{memory\_order\_relaxed} & All reordering are okay; only atomicity is required of this operation. \\ \hline
\texttt{memory\_order\_seq\_cst} & Same as \texttt{memory\_order\_acq\_rel}, plus a single total order exists in which all threads observe all modifications in the same order.\\ 
	\end{tabular}

\end{center}



The C++11 standard includes both strong and weak atomics. The weak ones are the ones where you get to specify the the memory ordering of load and store operating in a way that is not sequentially consistent. But we care about the standard, sequentially consistent kind of operation. \textit{Don't} use relaxed atomics unless you're an expert! Basically, a value that is seen from a memory load may come from the past or from the future (it's all relative, of course). If you want to dig into the details about an example, I recommend~\cite{bmref2}, which goes into the details of just how difficult it is to prove correctness. If that doesn't talk you out of it, I'm not sure what will.


\paragraph{Atomic Flags.} The simplest form of C++11 atomic is the {\tt atomic\_flag}.
Not surprisingly, this represents a boolean flag. You can clear the flag and test-and-set it.


\begin{verbatim}
#include <atomic>

atomic_flag f = ATOMIC_FLAG_INIT;
int foo() {
  f.clear();
  if (f.test_and_set()) {
    // was true
  }
}
\end{verbatim}

This returns the previous value. There is no assignment (=) operator for {\tt atomic\_flag}s. Although I guess in C++ you could define one if you wanted. This is kind of a dangerous thing about C++. If in C you see a line of code like \texttt{z = x + y;} you can have a pretty good idea about what it does and you can infer that there's some sort of natural meaning to the + operator there, like addition or concatenation. In C++, however, this same line of code tells you nothing, unless you know (1) the type of \texttt{x}, (2) the type of \texttt{y}, and (3) how the \texttt{+} operator is defined on those two operands \textit{in that order}. But I'm digressing.

\paragraph{More general C++ atomics.} Boolean flags are nice, but we want more.
C++11 supports arbitrary types as atomic. Here'a an example declaration:
\begin{verbatim}
#include <atomic>

atomic<int> x;
\end{verbatim}
The C++11 library implements atomics using lock-free operations for small types
and using mutexes for large types. The general types of operations that you can do with atomics are three: reads, writes, and RMW (read-modify-write) operations. C++ has syntax to make these all transparent.

\begin{verbatim}
// atomic reads and writes
#include <atomic>
#include <iostream>

std::atomic<int> ai;
int i;

int main() {
    ai = 4;
    i = ai;
    ai = i;
    std::cout << i;
}
\end{verbatim}
If you want, you can also use {\tt i = ai.load()} and {\tt ai.store(i)}.

As for RMW operations, consider {\tt ai++}. This is really

~~~{\tt tmp = ai.read(); tmp++; ai.write(tmp); }

But, hardware can do that atomically. It can also do other RMWs: {\tt +-, \&=, etc, compare-and-swap}.

More info on C++11 atomics:\\
\url{http://preshing.com/20130618/atomic-vs-non-atomic-operations/}

We talked about C++11 atomics. Is there a pthread equivalent? Nope, not really.

{\tt gcc} supports atomics via extensions: \\
\url{https://gcc.gnu.org/onlinedocs/gcc/_005f_005fatomic-Builtins.html}

OS X has atomics via OS calls: \\
\url{https://developer.apple.com/library/mac/documentation/Cocoa/Conceptual/Multithreading/ThreadSafety/ThreadSafety.html}

etc\ldots

Reference:
\url{http://stackoverflow.com/questions/1130018/unix-portable-atomic-operations}


\section*{The Compiler and You}
Making the compiler work for you is critical to programming for
performance. We'll therefore see some compiler implementation details
in this class. Understanding these details will help you reason about
how your code gets translated into machine code and thus executed.

\paragraph{Three Address Code.} Compiler analyses are much easier to
perform on simple expressions which have two operands and a
result---hence three addresses---rather than full expression trees.
Any good compiler will therefore convert a program's abstract syntax
tree into an intermediate, portable, three-address code before going
to a machine-specific backend.

Each statement represents one fundamental operation; we'll consider
these operations to be atomic. A typical statement looks like this:

\[ \qquad \mbox{result} := \mbox{operand$_1$}\:\mbox{operator}\:\mbox{operand$_2$} \]

Three-address code is useful for reasoning about data races. It is
also easier to read than assembly, as it separates out memory reads
and writes.

\paragraph{GIMPLE: \texttt{gcc}'s three-address code.} To see the GIMPLE representation 
of your code, pass {\tt gcc} the {\tt -fdump-tree-gimple} flag. You
can also see all of the three address code generated by the compiler;
use {\tt -fdump-tree-all}. You'll probably just be interested in the
optimized version.  

I suggest using GIMPLE to reason about your code at a low level
without having to read assembly. Let's take a few minutes to look at an example.


\subsection*{The {\tt restrict} qualifier} 
The {\tt restrict} qualifier on pointer {\tt p} tells
the compiler~\cite{cellperf} that it may assume that, in the scope of {\tt p},
the program will not use any other pointer {\tt q} to access the
data at {\tt *p}.

The {\tt restrict} qualifier is a feature introduced in C99: ``The
restrict type qualifier allows programs to be written so that
translators can produce significantly faster executables.''
  \begin{itemize}
    \item To request C99 in {\tt gcc}, use the {\tt -std=c99} flag.
  \end{itemize}

{\tt restrict} means: you are promising the
compiler that the pointer will never alias (another pointer will not
point to the same data) for the lifetime of the pointer.  Hence, two
pointers declared {\tt restrict} must never point to the same data.

In fact~\cite{cellperf} includes a contract that goes with the use of restrict:

\begin{quote}
I, [insert your name], a PROFESSIONAL or AMATEUR [circle one] programmer recognize that there are limits to what a compiler can do. I certify that, to the best of my knowledge, there are no magic elves or monkeys in the compiler which through the forces of fairy dust can always make code faster. I understand that there are some problems for which there is not enough information to solve. I hereby declare that given the opportunity to provide the compiler with sufficient information, perhaps through some key word, I will gladly use said keyword and not bitch and moan about how "the compiler should be doing this for me."

In this case, I promise that the pointer declared along with the restrict qualifier is not aliased. I certify that writes through this pointer will not effect the values read through any other pointer available in the same context which is also declared as restricted.

* Your agreement to this contract is implied by use of the restrict keyword ;)
\end{quote}

Of course, I highly recommend that you have your personal legal expert review this contract before you sign it. As I would for any contract. Contracts are serious business.

An example from Wikipedia:
\begin{verbatim}
  void updatePtrs(int* ptrA, int* ptrB, int* val) {
    *ptrA += *val;
    *ptrB += *val;
  }
\end{verbatim}
Would declaring all these pointers as {\tt restrict} generate better code?

Well, let's look at the GIMPLE.

\begin{verbatim}
void updatePtrs(int* ptrA, int* ptrB, int* val) {
 D.1609 = *ptrA;
 D.1610 = *val;
 D.1611 = D.1609 + D.1610;
 *ptrA = D.1611;
 D.1612 = *ptrB;
 D.1610 = *val;
 D.1613 = D.1612 + D.1610;
 *ptrB = D.1613;
}
\end{verbatim}

Now we can answer the question: ``Could any operation be left out if
all the pointers didn't overlap?''

\begin{itemize}
\item If {\tt ptrA} and {\tt val} are not equal, you don't have to
      reload the data on {\bf line 7}.
\item Otherwise, you would: there might be a call, somewhere:\\\verb+    updatePtrs(&x, &y, &x);+
\end{itemize}

Hence, this set of annotations allows optimization:
\begin{verbatim}
    void updatePtrs(int* restrict ptrA, 
                    int* restrict ptrB,
                    int* restrict val)
\end{verbatim}
Note: you can get the optimization by just declaring {\tt ptrA} and
      {\tt val} as {\tt restrict}; {\tt ptrB} isn't needed for this optimization

\paragraph{Summary of {\tt restrict}.}
Use {\tt restrict} whenever you know the pointer will not alias
another pointer (also declared {\tt restrict}).

It's hard for the compiler to infer pointer aliasing information;
it's easier for you to specify it. If the compiler has this information,
it can better optimize your code; in the body of a critical loop, that
can result in better performance.

A caveat: don't lie to the compiler, or you will get undefined behaviour.

Aside: {\tt restrict} is not the same as {\tt const}. {\tt const} data can still be
changed through an alias.



\input{bibliography.tex}

\end{document}
