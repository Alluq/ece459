\input{configuration}

\title{Lecture 13 --- OpenMP}

\author{Patrick Lam \\ \small \texttt{patrick.lam@uwaterloo.ca}}
\institute{Department of Electrical and Computer Engineering \\
  University of Waterloo}
\date{\today}


\begin{document}

\begin{frame}
  \titlepage

 \end{frame}

{ % all template changes are local to this group.
    \setbeamertemplate{navigation symbols}{}
    \begin{frame}[plain]
        \begin{tikzpicture}[remember picture,overlay]
            \node[at=(current page.center)] (pic) {
                \includegraphics[width=\paperwidth]{images/L12-turnstile-alewife.jpg}
            };
%            \draw node (current page.south) {Hello};
            \node[anchor=south] at (current page text area.south) { photo: Arnold Reinhold via Wikimedia Commons };
        \end{tikzpicture}
     \end{frame}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[containsverbatim]
  \frametitle{From pthreads to OpenMP}

\vspace*{-3em}
\Large
\begin{changemargin}{1.5cm}
    So far: Pthreads and \\
          \hspace*{4em}automatic parallelization.\\[1em]
    Next: ``Manual'' parallelization \\
          \hspace*{4em}using OpenMP.
\end{changemargin}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[containsverbatim]
  \frametitle{OpenMP allows you to specify parallelization.}

\vspace*{-3em}  
\Large
\begin{changemargin}{1.5cm}
    OpenMP = Open Multiprocessing.\\[2em]
    You specify parallelization; \\
    \hspace*{4em} compiler implements.\\[1em]
    ``I want 10 turnstiles.''
\end{changemargin}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[containsverbatim]
  \frametitle{Modern compilers support OpenMP.}
\vspace*{-3em}
\Large
\begin{changemargin}{1.5cm}
    All major compilers have OpenMP \\
    \qquad (GCC, clang, Solaris,
      Intel, Microsoft).\\[1em]

  Use OpenMP\footnote{More information:
    \url{https://computing.llnl.gov/tutorials/openMP/}} by specifying\\
  \hspace*{4em} directives in source code. \\[1em]
  C/C++: pragmas of the
  form \verb+#pragma omp ...+
\end{changemargin}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[containsverbatim]
  \frametitle{OpenMP separates parallelization implementation \\ from algorithm implementation.}

\large
  
\begin{changemargin}{1.5cm}
    OpenMP uses compiler directives---\\
    \hspace*{2em} compile same codebase for serial or parallel.

  \begin{lstlisting}[language=C,morekeywords={foreach,pragma,omp,parallel,single,nowait,task,untied,barrier,taskyield}]
void calc (double *array1, double *array2, int length) {
    #pragma omp parallel for
    for (int i = 0; i < length; i++) {
        array1[i] += array2[i];
    }
}
  \end{lstlisting}

    Enables incremental parallelization of the program.\\
    (Start with the hotspots.)

  Without OpenMP: \\ \quad Could compiler parallelize this automatically?
\end{changemargin}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[containsverbatim]
  \frametitle{{\tt \#pragma} forces the compiler to parallelize the loop.}

\large
  
\begin{changemargin}{1cm}
  \begin{itemize}
    \item It does not look at loop contents, only loop bounds.
    \item \alert{It is your responsibility to make sure the code is safe.}
  \end{itemize}
  OpenMP will always start parallel threads if you tell it to,\\
  dividing iterations contiguously among the threads.\\[1em]

  You don't need to declare {\tt restrict}, but it's a good idea.\\
  Need {\tt restrict} for auto-parallelization (non-OpenMP).
\end{changemargin}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[containsverbatim]
  \frametitle{{\tt \#pragma omp parallel for} contains three parts.}

\begin{changemargin}{1cm}
\large
  Let's look at the parts of this \verb+#pragma+.\\[1em]

  \begin{itemize}
    \item \verb+#pragma omp+ indicates an OpenMP directive;
    \vfill
    \item {\tt parallel} indicates the start of a parallel region.
    \vfill
    \item {\tt for} tells OpenMP: run the next {\tt for} loop in parallel.
  \end{itemize}
  ~\\[-1em]

  When you run the parallelized program, \\ the runtime library starts
  a number of threads \& \\  assigns a subrange of the range to 
  each of the threads.
\end{changemargin}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{OpenMP can parallelize certain loops.}

  
\begin{verbatim}
    for (int i = 0; i < length; i++) { ... }
\end{verbatim}~\\[1em]

\begin{changemargin}{1cm}
    Can only parallelize loops which satisfy these conditions:
\begin{itemize}
\item must be of the form:\\{\tt ~~for (init expr; test expr; increment expr)};
\item loop variable must be integer (signed or unsigned), pointer, or a C++
random access iterator;
\item loop variable must be initialized to one end of the range;
\item loop increment amount must be loop-invariant (constant with respect to the loop body); and
\item test expression must be one of {\tt >}, {\tt >=}, {\tt <}, or {\tt <=}, and the comparison value (bound) must be loop-invariant.
\end{itemize}

{\bf Note:} these restrictions thus also apply to\\ \qquad \qquad automatically parallelized
loops.
\end{changemargin}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[containsverbatim]
  \frametitle{OpenMP generates parallelized code.}

  \begin{enumerate}
    \item Compiler generates code to spawn a \structure{team}
of threads; automatically splits off worker-thread code into a
separate procedure.
    \item Generated code uses {\tt fork-join} parallelism; when the
master thread hits a parallel region, it gives work to the worker
threads, which execute and report back.
    \item Afterwards, the master thread
continues running, while the worker threads wait for more work .
  \end{enumerate}

\begin{changemargin}{1cm}
~\\
You can specify the number of threads by setting the
\verb+OMP_NUM_THREADS+ environment variable. \\

(You can also adjust by calling 
\verb+omp_set_num_threads()+).

\begin{itemize}
  \item Solaris compiler tells you what it did if you use the flags \verb+-xopenmp -xloopinfo+, or \verb+er_src+.
\end{itemize}
\end{changemargin}
  


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{You can control variable scoping in OpenMP.}

  
\begin{changemargin}{1.5cm}
\Large
  Concept: thread-local variables (\structure{private})\\
    \hspace*{4em}  vs shared~variables.
  \begin{itemize}
    \item Writes to private variables:\\
\qquad visible only to writing thread.
    \item Writes to shared variables:\\ 
\qquad visible to all threads.
  \end{itemize}
\end{changemargin}
  

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{In example, {\tt length} could be shared or private.}

  

\begin{verbatim}
    for (int i = 0; i < length; i++) { ... }
\end{verbatim}

\large
\begin{changemargin}{1cm}
  \begin{itemize}
    \item if {\tt length} was private, \\
\hspace*{2em} you'd have to copy
in appropriate initial value.
    \item {\tt array} variables must be shared.
  \end{itemize}
\end{changemargin}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{OpenMP has sensible default scoping.}

\begin{changemargin}{2cm}
{\Large Let's look at the defaults that OpenMP uses to parallelize the {\tt parallel-for} code:}
\begin{lstlisting}
% er_src parallel-for.o
     1.   <Function: calc>
    
    Source OpenMP region below has tag R1
    Private variables in R1: i
    Shared variables in R1: array2, length, array1
     2.     #pragma omp parallel for
\end{lstlisting}
\end{changemargin}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Solaris tells you OpenMP parallelization information.}
\begin{changemargin}{2cm}
\begin{lstlisting}
    Source loop below has tag L1
    L1 autoparallelized
    L1 parallelized by explicit user directive
    L1 parallel loop-body code placed in function _$d1A2.calc 
                     along with 0 inner loops
    L1 multi-versioned for loop-improvement:
                     dynamic-alias-disambiguation. 
        Specialized version is L2
     3.     for (int i = 0; i < length; i++) {
     4.       array1[i] += array2[i];
     5.     }
     6.   }
\end{lstlisting}
\end{changemargin}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Default Variable Scoping Rules: \\
loop vars private, parallel vars private, others shared.}

\begin{changemargin}{1.5cm}
\large
\begin{itemize}
  \item Loop variables are private.
  \item Variables defined in parallel code are private.
  \item Variables defined outside the parallel region are shared.
\end{itemize}
~\\

You can disable the default rules \\
by specifying {\tt default(none)} on the {\tt parallel}, \\
or you can give explicit scoping:

\begin{lstlisting}
#pragma omp parallel for private(i) 
                         shared(length, array1, array2)
\end{lstlisting}
\end{changemargin}


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{What is appropriate scope for reduction variable?}
  
\begin{changemargin}{1.5cm}
\large
Consider a reduction, e.g.
\begin{lstlisting}[language=C,morekeywords={foreach,pragma,omp,parallel,single,nowait,task,untied,barrier,taskyield}]
for (int i = 0; i < length; i++)
    total += array[i];
\end{lstlisting}

What is the appropriate scope for {\tt total}? \\
\pause
Well, it should be
\structure{shared}.

\begin{itemize}
 \item We want each thread to be able to write to it. \pause
 \item But, is there a race condition? (of course)
\end{itemize}

Aha! OpenMP deals with reductions as a special case:


\begin{lstlisting}
#pragma omp parallel for reduction (+:total)
\end{lstlisting}

specifies that the {\tt total} variable is the accumulator for a
reduction over the {\tt +} operator.
\end{changemargin}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{OpenMP lets you access private data outside a parallel region (on request).}

\begin{changemargin}{1.5cm}
\large
Sometimes you want \structure{private} variables,\\
but want them initialized
before the loop.\\[1em]

Consider this (silly) code:

\begin{lstlisting}
int data=1;
#pragma omp parallel for private(data)
for (int i = 0; i < 100; i++)
    printf ("data=%d\n", data);
\end{lstlisting}


\begin{itemize}
  \item {\tt data} is private, so OpenMP will not copy in initial 1.
  \item To make OpenMP copy data before threads start, use
    {\tt firstprivate(data)}.
  \item To publish a variable after the (sequentially) last iteration of the loop, use
    {\tt lastprivate(data)}.
\end{itemize}
  
\end{changemargin}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{OpenMP supports thread-private data.}

\begin{changemargin}{1cm}
\large
    You might have a global variable, \\
for which each thread should have a persistent local copy\\
\hspace*{3em} (lives across parallel regions.)\\[1em]
  \begin{itemize}
    \item Use the {\tt threadprivate} directive.
    \item Add {\tt copyin} for something like
      {\tt firstprivate}.
    \item There is no {\tt lastprivate}: data accessible after 
      loop.
  \end{itemize}
\end{changemargin}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Thread-Private Data Example (1)}

\large
\begin{changemargin}{1cm}
  \begin{lstlisting}[language=C,morekeywords={foreach,pragma,omp,parallel,single,nowait,task,untied,barrier,taskyield}]
#include <omp.h>
#include <stdio.h>

int tid, a, b;

#pragma omp threadprivate(a)

int main(int argc, char *argv[])
{
    printf("Parallel #1 Start\n");
    #pragma omp parallel private(b, tid)
    {
        tid = omp_get_thread_num();
        a = tid;
        b = tid;
        printf("T%d: a=%d, b=%d\n", tid, a, b);
    }

    printf("Sequential code\n");
  \end{lstlisting}
  
\end{changemargin}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Thread-Private Data Example (2)}

  
\large
\begin{changemargin}{1cm}
  \begin{lstlisting}[language=C,morekeywords={foreach,pragma,omp,parallel,single,nowait,task,untied,barrier,taskyield}]
    printf("Parallel #2 Start\n");
    #pragma omp parallel private(tid)
    {
        tid = omp_get_thread_num();
        printf("T%d: a=%d, b=%d\n", tid, a, b);
    }

    return 0;
}    
  \end{lstlisting}
\end{changemargin}
  
  \begin{center}
    \begin{columns}[c]
      \column{1.5in}
        \begin{lstlisting}
% ./a.out
Parallel #1 Start
T6: a=6, b=6
T1: a=1, b=1
T0: a=0, b=0
T4: a=4, b=4
T2: a=2, b=2
T3: a=3, b=3
T5: a=5, b=5
T7: a=7, b=7
        \end{lstlisting}
      \column{1.5in}
        \begin{lstlisting}
Sequential code
Parallel #2 Start
T0: a=0, b=0
T6: a=6, b=0
T1: a=1, b=0
T2: a=2, b=0
T5: a=5, b=0
T7: a=7, b=0
T3: a=3, b=0
T4: a=4, b=0
        \end{lstlisting}
    \end{columns}
  \end{center}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Atomic ensures a storage location is updated atomically.}

  \Large
  \begin{changemargin}{1.5cm}
  \begin{center}
    {\tt \#pragma omp }{\bf atomic} [{\bf read $\mid$ write $\mid$ update $\mid$ capture}]\\
    {\it expression-stmt}
  \end{center}~\\

    Atomic is more efficient than\\
 using critical sections. \\
      \hspace*{2em} (or else why would they
      include it?)\\[2em]

  \end{changemargin}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Atomic expressions include read, write, update, capture.}

  \begin{changemargin}{1cm}

  {\bf read expression:} {\tt v = x;}\\[1em]

  {\bf write expression:} {\tt x = expr;}\\[1em]

  {\bf update expression:} {\tt x++;} {\tt x{-}-;} {\tt ++x;} {\tt -{-}x;}\\
  \hspace{9em}{\tt x binop= expr;} {\tt x = x binop expr;}\\[1em]

    {\tt expr} must not access the same location as {\tt v} or {\tt x}.\\
    {\tt v} and {\tt x} must not access the same location; must be
      primitives.\\
    All operations to {\tt x} are atomic.\\[2em]

  {\bf capture expression:} {\tt v = x++;} {\tt v = x{-}-;} {\tt v = ++x;}
  {\tt v = -{-}x;}\\ \hspace{9.2em}{\tt v = x binop= expr;}

  Performs the indicated update. Also stores the original or
  final value computed.
  \end{changemargin}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{OpenMP can collapse loops.}


  \begin{changemargin}{2cm}
\large
Normally, it's best to parallelize the outermost loop.
  
But, consider this code:

  \begin{lstlisting}[language=C,morekeywords={foreach,pragma,omp,parallel,single,nowait,task,untied,barrier,taskyield}]
#include <math.h>
int main() {
    double array[2][10000];
    #pragma omp parallel for collapse(2)
    for (int i = 0; i < 2; i++)
      for (int j = 0; j < 10000; j++)
        array[i][j] = sin(i+j);
    return 0;
}
  \end{lstlisting}


  \begin{itemize}
  \item Would parallelizing this outer loop benefit us?\\
    What about the inner loop?
  \end{itemize}

  OpenMP supports \emph{collapsing} loops:

  \begin{itemize}
    \item Creates a single loop for all the iterations of the two loops.
    \item Outer loop only enables the use of 2 threads.
    \item Collapsed loop lets us use up to 20,000 threads.
  \end{itemize}
  \end{changemargin}
  

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Better scheduling can improve performance.}

  
  \begin{changemargin}{2cm}
    \large
  OpenMP's default mode: \emph{Static scheduling}.
  \begin{itemize}
    \item Assumes each iteration takes same running time.
  \end{itemize}

  Does that assumption hold for this code?

  \begin{lstlisting}[language=C,morekeywords={foreach,pragma,omp,parallel,single,nowait,task,untied,barrier,taskyield}]
double calc(int count) {
    double d = 1.0;
    for (int i = 0; i < count*count; i++) d += d;
    return d;
}

int main() {
    double data[200][100];
    int i, j;
    #pragma omp parallel for private(i, j) shared(data)
    for (int i = 0; i < 200; i++) {
        for (int j = 0; j < 200; j++) {
            data[i][j] = calc(i+j);
        }
    }
    return 0;
}
  \end{lstlisting}
  \end{changemargin}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Example gives sublinear scaling with static scheduling.}

\large


  \begin{changemargin}{1cm}
  \begin{itemize}
    \item Earlier iterations are faster than later iterations.\\
          Result: sublinear scaling---\\ must wait for all iterations to finish.\\[1em]
    \item Turn on \emph{dynamic schedule} mode\\ by adding
      {\tt schedule(dynamic)} to the pragma:
      \begin{itemize}
        \item Breaks the work into chunks;
        \item Distributes the work to each thread in chunks;
        \item Higher overhead;
        \item Default chunk size of 1\\ (can modify, e.g. {\tt schedule(dynamic, n/50)}).
      \end{itemize}
  \end{itemize}
  \end{changemargin}


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{OpenMP supports yet more scheduling options: \\
{\tt guided}, {\tt auto}, and {\tt runtime}.}

  \begin{changemargin}{1.5cm}
\large
      
  \begin{itemize}
    \item {\tt guided} changes the chunk size based on work
          remaining.
          
      \begin{itemize}
        \item Default minimum chunk size = 1 (can modify)
      \end{itemize}
    \item {\tt auto} lets OpenMP decide what's best.
    \item {\tt runtime} doesn't pick a mode until runtime.
      \begin{itemize}
        \item Tune with \verb+OMP_SCHEDULE+ environment variable
      \end{itemize}
  \end{itemize}
  \end{changemargin}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Why more than for?}

\large
  
  \begin{changemargin}{.5cm}
  So far, we've seen how to parallelize (some) {\tt for} loops.\\[1em]

  Less powerful than Pthreads. (Also harder to get wrong.)\\[1em]

  Reflects OpenMP's scientific-computation heritage.\\[1em]

  Today, we need more general parallelism, not just matrices.
  \end{changemargin}


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{OpenMP supports parallel sections---an example.}

\large
  
  \begin{changemargin}{.5cm}
  Parallel sections: purely-static mechanism for specifying independent work units which should run in
  parallel.\\[1em]

  Linked list example:

{\small
\begin{lstlisting}[language=C,morekeywords={foreach,pragma,omp,parallel,single,nowait,task,untied,barrier,taskyield}]
  #include <stdlib.h>

  typedef struct s { struct s* next; } S;

  void setuplist (S* current) {
    for (int i = 0; i < 10000; i++) {
      current->next = (S*) malloc (sizeof(S));
      current = current->next;
    }
    current->next = NULL;
  }
  \end{lstlisting}
}

  \end{changemargin}


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{OpenMP can process two linked lists in parallel \\ with parallel sections.}
  
  \begin{changemargin}{1cm}

  (Exactly) 2 linked lists:
{\small
  \begin{lstlisting}
  int main() {
    S var1, var2;
    #pragma omp parallel sections
    {
      #pragma omp section
      { setuplist (&var1); }
      #pragma omp section
      { setuplist (&var2); }
    }
    return 0;
  }
\end{lstlisting}}

  Parallelism structure explicitly visible.\\[1em]
  Finite number of threads.\\[1em]
  (What's another barrier to more general parallelism?)

  \end{changemargin}


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Parallel sections can help avoid collapsing loops.}
  

  \begin{changemargin}{2cm}
  Sometimes you don't want to collapse loops.\\[1em]

  Example: (better example in PDF notes!)\\[1em]

{\small
  \begin{lstlisting}[language=C,morekeywords={foreach,pragma,omp,parallel,single,nowait,task,untied,barrier,taskyield}]
    #pragma omp parallel sections
    {
      #pragma omp section
      { 
          #pragma omp parallel for
          for (int i = 0; i < 1000; i++) { ... } 
      }
      #pragma omp section
      {
          #pragma omp parallel for
          for (int i = 0; i < 1000; i++) { ... } 
      }
    }
\end{lstlisting}}

  To enable nested parallelism, call \verb+omp_set_nested(1)+\\ or
  set \verb+OMP_NESTED+. (Runtime might refuse.)\\[1em]

  \end{changemargin}
  


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{OpenMP tasks support irregular parallelism.}

  \begin{changemargin}{1cm}
\large
  Tasks: main new feature in OpenMP 3.0.\\[1em]

  \verb+#pragma omp task+:\\ \qquad code splits off and scheduled to run later.\\[1em]

  More flexible than parallel sections: 
\vspace*{-1em}
  \begin{itemize}
   \item can run as many threads as needed;
   \item tasks do not need to join (like detached threads).
  \end{itemize}
  OpenMP does the task-to-thread mapping---\\ lower overhead.
  \end{changemargin}
  


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Examples of tasks}
  

\Large
  \begin{changemargin}{1cm}
   Two examples:
\vspace*{-1em}
   \begin{itemize}
     \item web server\\ \quad unstructured requests
     \item user interface\\ \quad allows users to start concurrent tasks
   \end{itemize}
  \end{changemargin}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Boa webserver main loop example}
  

  \begin{changemargin}{2cm}
{\small
\begin{lstlisting}[language=C,morekeywords={foreach,pragma,omp,parallel,single,nowait,task,untied,barrier,taskyield}]
#pragma omp parallel
  /* a single thread manages the connections */
  #pragma omp single nowait
  while (!end) {
    process any signals
    foreach request from the blocked queue {
      if (request dependencies are met) {
        extract from the blocked queue
        /* create a task for the request */
        #pragma omp task untied
          serve_request(request);
      }
    }
    if (new connection) {
      accept_connection();
      /* create a task for the request */
      #pragma omp task untied
        serve_request(new connection);
    }
    select();
  }
\end{lstlisting}
}
  \end{changemargin}
  


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Other OpenMP qualifiers}

  
    {\tt untied}: lifts restrictions on task-to-thread mapping.\\[1em]

    {\tt single}: only one thread runs the next statement (not $N$ copies).\\[1em]

    {\tt flush} directive: write all values in registers or cache to memory.\\[1em]

    {\tt barrier}: wait for all threads to complete. (OpenMP also has implicit
barriers at ends of parallel sections.)\\[1em]

    OpenMP also supports critical sections (one thread at a time), atomic
 sections, and typical mutex locks (\verb+omp_set_lock+,
 \verb+omp_unset_lock+).
  

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% %%%%%%%%%
\begin{frame}[fragile]
  \frametitle{OpenMP Directives Warning: \\
  Write code so that eliding OpenMP gives a valid program.}
  
  For instance, this is wrong:
  \begin{lstlisting}[language=C,morekeywords={foreach,pragma,omp,parallel,single,nowait,task,untied,barrier,taskyield}]
if (a != 0)
    #pragma omp barrier // wrong!
if (a != 0)
    #pragma omp taskyield // wrong!
  \end{lstlisting}

  Use this instead:
  \begin{lstlisting}[language=C,morekeywords={foreach,pragma,omp,parallel,single,nowait,task,untied,barrier,taskyield}]
if (a != 0) {
    #pragma omp barrier
}
if (a != 0) {
    #pragma omp taskyield
}
  \end{lstlisting}
  

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}

