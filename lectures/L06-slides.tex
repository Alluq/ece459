\input{configuration}

\title{Lecture 6 --- Race Conditions \& Synchronization }

\author{Patrick Lam \& Jeff Zarnett \\ \small \texttt{p.lam@ece.uwaterloo.ca}, \texttt{jzarnett@uwaterloo.ca}}
\institute{Department of Electrical and Computer Engineering \\
  University of Waterloo}
\date{\today}


\begin{document}

\begin{frame}
  \titlepage

 \end{frame}



\begin{frame}
\frametitle{Race Conditions }

\vfill
\begin{quote}
\textit{
	``Knock knock.''\\
	``Race Condition.''\\
	``Who's there?''
	}
\end{quote}
\end{frame}



\begin{frame}
\frametitle{Define A Race Condition}

A race occurs when you have two concurrent accesses to the
same memory location, at least one of which is a {\bf write}.

This definition is a little bit strict. 

We could also say that there is a race condition if there is some form of output, such as writing to the console. 

If one thread is going to write ``1'' to the console and another is going to write ``2'', then we could have a race condition. 

If there is no co-ordination, we could get output of ``12'' or ``21''. 

If the order here is unimportant, there's no issue; but if one order is correct, then the appearance of the other is a bug.

\end{frame}



\begin{frame}
\frametitle{Matters of State}

When there's a race, the final state may not be the same as running
one access to completion and then the other. 

But it ``usually'' is.  It's nondeterministic. 

The fact that the output is often ``12'' and only very occasionally ``21'' may make it very difficult to track down the source of the problem. 

\end{frame}



\begin{frame}
\frametitle{Hazards}

In other situations (e.g., processor design) these are sometimes referred to as data hazards or dependencies. 

\begin{enumerate}
	\item \textbf{RAW} (Read After Write)	
	\item \textbf{WAR} (Write After Read)
	\item \textbf{WAW} (Write After Write)
	\item \textbf{RAR} (Read After Read) - No such hazard! 
\end{enumerate}


\end{frame}



\begin{frame}[fragile]
\frametitle{It's a Kind of Hazard}
Race conditions typically arise between variables shared
between threads.
{\scriptsize
\begin{verbatim}
#include <stdlib.h>
#include <stdio.h>
#include <pthread.h>

void* run1(void* arg) {
    int* x = (int*) arg;
    *x += 1;
}

void* run2(void* arg) {
    int* x = (int*) arg;
    *x += 2;
}

int main(int argc, char *argv[])
{
    int* x = malloc(sizeof(int));
    *x = 1;
    pthread_t t1, t2;
    pthread_create(&t1, NULL, &run1, x);
    pthread_join(t1, NULL);
    pthread_create(&t2, NULL, &run2, x);
    pthread_join(t2, NULL);
    printf("%d\n", *x);
    free(x);
    return EXIT_SUCCESS;
}
\end{verbatim}
}

\end{frame}



\begin{frame}[fragile]
\frametitle{It's a Kind of Hazard II}

{\scriptsize
\begin{verbatim}
int main(int argc, char *argv[])
{
    int* x = malloc(sizeof(int));
    *x = 1;
    pthread_t t1, t2;
    pthread_create(&t1, NULL, &run1, x);
    pthread_create(&t2, NULL, &run2, x);
    pthread_join(t1, NULL);
    pthread_join(t2, NULL);
    printf("%d\n", *x);
    free(x);
    return EXIT_SUCCESS;
}
\end{verbatim}
}

Now do we have a race?

\end{frame}



\begin{frame}[fragile]
\frametitle{Trace the Race}

What are the possible outputs? (Assume that initially {\tt *x} is 1.)
We'll look at compiler intermediate code (three-address code) to tell.

\hspace*{.2\textwidth}\begin{minipage}{.8\textwidth}
\begin{verbatim}
run1                          run2   
D.1 = *x;                     D.1 = *x;
D.2 = D.1 + 1;                D.2 = D.1 + 2
*x = D.2;                     *x = D.2;
  \end{verbatim}
\end{minipage}

Memory reads and writes are key in data~races.

\end{frame}



\begin{frame}
\frametitle{Trace the Race}
Let's call the read and write from {\tt run1} R1 and W1; R2 and W2
from {\tt run2}.

Here are all possible orderings:
  \begin{center}
    \begin{tabular}{llll|l}
\multicolumn{4}{c|}{Order} & {\tt *x}\\
\hline
R1 & W1 & R2 & W2 & 4 \\
R1 & R2 & W1 & W2 & 3 \\
R1 & R2 & W2 & W1 & 2 \\
R2 & W2 & R1 & W1 & 4 \\
R2 & R1 & W2 & W1 & 2 \\
R2 & R1 & W1 & W2 & 3 \\
    \end{tabular}
  \end{center}

\end{frame}



\begin{frame}
\frametitle{Synchronization}

You'll need some sort of synchronization to get sane results from
multithreaded programs. 

We'll start by talking about how to use
mutual exclusion in Pthreads.


\end{frame}



\begin{frame}
\frametitle{Mutual Exclusion}

Mutexes are the most basic type of synchronization.
As a reminder:
    \begin{itemize}
    \item Only one thread can access code protected by a mutex at a time.
    \item All other threads must wait until the mutex is free before they can
      execute the protected code.
    \end{itemize}


\end{frame}


\begin{frame}[fragile]
\frametitle{Using a Mutex}

  Here's an example of using mutexes:
    
    \begin{tabular}{ll}
      \begin{minipage}{.65\textwidth}
        {\bf PThreads}
{\scriptsize
  \begin{verbatim}
pthread_mutex_t m1_static = PTHREAD_MUTEX_INITIALIZER;
pthread_mutex_t m2_dynamic;

pthread_mutex_init(&m2_dynamic, NULL);
...
pthread_mutex_destroy(&m1_static);
pthread_mutex_destroy(&m2_dynamic);
  \end{verbatim}
  }
      \end{minipage}
      \begin{minipage}{.35\textwidth}

        {\bf C++11}
{\scriptsize
  \begin{verbatim}
mutex m1;
mutex * m2;

m2 = new mutex();
// ...

delete (m2);
  \end{verbatim}
  }
      \end{minipage}
    \end{tabular}

You can initialize mutexes statically (as with {\tt m1\_static}) or
dynamically ({\tt m2\_dynamic}). 

If you want to include attributes,
you need to use the dynamic version.

\end{frame}



\begin{frame}
\frametitle{Mutex Attributes}

 Both threads and mutexes use the notion of attributes.
 

  \begin{itemize}
    \item {\bf Protocol}: specifies the protocol used to prevent priority
      inversions for a mutex.
    \item {\bf Prioceiling}: specifies the priority ceiling of a mutex.
    \item {\bf Process-shared}: specifies the process sharing of a mutex.
  \end{itemize}
  
  You can specify a mutex as {\it process shared} so that you can access it
  between processes.

\end{frame}



\begin{frame}[fragile]
\frametitle{Mutex Example}

   \begin{tabular}{ll}
      \begin{minipage}{.5\textwidth}
        {\bf PThreads}
  \begin{verbatim}
// code
pthread_mutex_lock(&m1);
// protected code
pthread_mutex_unlock(&m1);
// more code
  \end{verbatim}
      \end{minipage}&
      \begin{minipage}{.35\textwidth}
        {\bf C++11 Threads}
  \begin{verbatim}
// code
m1.lock();
// protected code
m1.unlock();
// more code
  \end{verbatim}
      \end{minipage}
    \end{tabular}

  \begin{itemize}
    \item Everything within the {\tt lock} and {\tt unlock} is protected.
    \item Be careful to avoid deadlocks if you are using multiple mutexes (always
acquire locks in the same order across threads).
    \item Another useful primitive is {\tt pthread\_mutex\_trylock}.
later.
  \end{itemize}


\end{frame}



\begin{frame}[fragile]
\frametitle{Locks and Data Races}

Why are we bothering with locks? Data races. A data race occurs when
two concurrent actions access the same variable and at least one of
them is a {\bf write}. (This shows up on Assignment 1!)

  \begin{verbatim}
static int counter = 0;

void* run(void* arg) {
    for (int i = 0; i < 100; ++i) {
        ++counter;
    }
}

int main(int argc, char *argv[]) {
    // Create 8 threads
    // Join 8 threads
    printf("counter = %i\n", counter);
}
  \end{verbatim}


\end{frame}



\begin{frame}[fragile]
\frametitle{Use Mutexes}

 \begin{verbatim}
static pthread_mutex_t mutex = PTHREAD_MUTEX_INITIALIZER;
static int counter = 0;

void* run(void* arg) {
    for (int i = 0; i < 100; ++i) {
        pthread_mutex_lock(&mutex);
        ++counter;
        pthread_mutex_unlock(&mutex);
    }
}

int main(int argc, char *argv[]) {
    // Create 8 threads
    // Join 8 threads
    pthread_mutex_destroy(&mutex);
    printf("counter = %i\n", counter);
}
  \end{verbatim}

\end{frame}



\begin{frame}
\frametitle{Mutex Recap}

\begin{itemize}
\item Call {\tt lock} on mutex $\ell_1$. Upon return from
      {\tt lock}, your thread has exclusive access to $\ell_1$ until it
      {\tt unlock}s it.
\item Other calls to {\tt lock} $\ell_1$ will not return
      until {\tt m1} is available.
\end{itemize}

\end{frame}



\begin{frame}
\frametitle{Protect the End Zone}

Key idea: locks protect resources; only one thread
can hold a lock at a time. 

A second thread trying to obtain the lock
(i.e. \alert{contending} for the lock) has to wait, or \alert{block},
until the first thread releases the lock. 

So only one thread has
access to the protected resource at a time. 

The code between the lock
acquisition and release is known as the \alert{critical region} or \alert{critical section}.

\end{frame}


\begin{frame}
\frametitle{Try, Try Again}

Some mutex implementations also provide a ``try-lock'' primitive.

This grabs the lock if it's available, or returns control to the
thread if it's not.

This enables the thread to do something else. (Kind of
like non-blocking I/O!)

\end{frame}



\begin{frame}
\frametitle{Don't Lock Too Much}

Excessive use of locks can serialize programs. 

Consider two resources
$A$ and $B$ protected by a single lock $\ell$. 

Then a thread that's
just interested in $B$ still has acquire $\ell$, which requires it to
wait for any other thread working with $A$.

Example: Linux Big Kernel Lock

\end{frame}



\begin{frame}
\frametitle{Spinlocks}

Spinlocks are a variant of mutexes, where the
waiting thread repeatedly tries to acquire the lock instead of sleeping.

Use spinlocks when you expect critical sections to finish 
quickly.

Spinning
for a long time consumes lots of CPU resources.

 Many lock
implementations use both sleeping and spinlocks: spin for a bit,
then sleep longer.


\end{frame}



\begin{frame}
\frametitle{Why Use Spinlocks?}

When would we ever want to use a spinlock?

What we normally expect is to block until the lock becomes available. 

But that means a process switch, and then a switch back in the future when the lock is available.  This takes nonzero time. 

It's optimal to use a spinlock if the amount of time we expect to wait for the lock is less than the amount of time it would take to do two process switches. 

As long as we have a multicore system.

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Read-Write Locks}

  Two observations:
  \begin{itemize}
    \item If there are only reads, there's no datarace.
    \item Often, writes are relatively rare.
  \end{itemize}
  With mutexes/spinlocks, you have to lock the data, even for a read,
      since a write could happen.\\[1em]

  But, most of the time, reads can happen in parallel, as long as
      there's no write.\\[1em]

  Solution: Multiple threads can hold a read lock\\ \hspace*{2em} ({\tt pthread\_rwlock\_rdlock})\\
      but only one thread may hold the associated write lock\\ \hspace*{2em} ({\tt pthread\_rwlock\_wrlock});\\
      grabbing the write waits until  current readers are done.
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Semaphores}

    Semaphores have a {\tt value}.
      You specify initial {\tt value}.\\[1em]
    Semaphores allow sharing of a \# of instances of a resource.\\[1em]
    Two fundamental operations: {\tt wait} and {\tt post}.\\[1em]
  \begin{itemize}
    \item {\tt wait} is like {\tt lock}; reserves the resource and decrements the value.
      \begin{itemize}
        \item If value is 0, sleep until value is greater than 0.
      \end{itemize}
    \item {\tt post} is like {\tt unlock}; releases the resource and increments the value.
  \end{itemize}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Barriers}


    Allows you to ensure that (some subset of) a collection 
    of threads all reach the barrier before finishing.\\[1em]

    Pthreads: A barrier is a {\tt pthread\_barrier\_t}.\\[1em]

    Functions: {\tt \_init()} (parameter: how many threads the barrier
    should wait for) and {\tt \_destroy()}.\\[1em]

    Also {\tt \_wait()}: similar to {\tt pthread\_join()}, but waits
      for the specified number of threads to arrive at the barrier

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Lock-Free Algorithms}


    We'll talk more about this in a few weeks.\\[1em]

    Modern CPUs support atomic operations, such as compare-and-swap, which
enable experts to write lock-free code.\\[1em]

    Lock-free implementations are extremely complicated and must still contain certain synchronization constructs.

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Semaphores Usage}
  

  \begin{lstlisting}
#include <semaphore.h>

int sem_init(sem_t *sem, int pshared, unsigned int value);
int sem_destroy(sem_t *sem);
int sem_post(sem_t *sem);
int sem_wait(sem_t *sem);
int sem_trywait(sem_t *sem);
  \end{lstlisting}

  \begin{itemize}
    \item Also must link with {\tt -pthread} (or {\tt -lrt} on Solaris).
    \item All functions return {\tt 0} on success.
    \item Same usage as mutexes in terms of passing pointers.
  \end{itemize}~\\[1em]
    How could you use as {\tt semaphore} as a {\tt mutex}?
    \begin{itemize}
    \item<2-> If the initial {\tt value} is 1 and you use {\tt wait} to lock
      and {\tt post} to unlock, it's equivalent to a {\tt mutex}.
    \end{itemize}


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Semaphores for Signalling}


  Here's an example from the book. How would you make this always print
  ``Thread 1'' then ``Thread 2'' using semaphores?

  \begin{lstlisting}
#include <pthread.h>
#include <stdio.h>
#include <semaphore.h>
#include <stdlib.h>

void* p1 (void* arg) { printf("Thread 1\n"); }

void* p2 (void* arg) { printf("Thread 2\n"); }

int main(int argc, char *argv[])
{
    pthread_t thread[2];
    pthread_create(&thread[0], NULL, p1, NULL);
    pthread_create(&thread[1], NULL, p2, NULL);
    pthread_join(thread[0], NULL);
    pthread_join(thread[1], NULL);
    return EXIT_SUCCESS;
}
  \end{lstlisting}

\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Semaphores for Signalling}


  Here's their solution. Is it actually correct?

  \begin{lstlisting}
sem_t sem;
void* p1 (void* arg) {
  printf("Thread 1\n");
  sem_post(&sem);
}
void* p2 (void* arg) {
  sem_wait(&sem);
  printf("Thread 2\n");
}

int main(int argc, char *argv[])
{
    pthread_t thread[2];
    sem_init(&sem, 0, /* value: */ 1);
    pthread_create(&thread[0], NULL, p1, NULL);
    pthread_create(&thread[1], NULL, p2, NULL);
    pthread_join(thread[0], NULL);
    pthread_join(thread[1], NULL);
    sem_destroy(&sem);
}
  \end{lstlisting}


\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Semaphores for Signalling}

  

  \begin{enumerate}
    \item {\tt value} is initially 1.
    \vfill
    \item Say {\tt p2} hits its {\tt sem\_wait} first and succeeds.
    \vfill
    \item {\tt value} is now 0 and {\tt p2} prints ``Thread 2'' first.
  \end{enumerate}
  \begin{itemize}
    \item If {\tt p1} happens first, it would just increase
      {\tt value} to 2.\vfill
    \item<2-> Fix: set the initial {\tt value} to \alert{0}.\\[1em]
Then, if {\tt p2} hits its {\tt sem\_wait} first, it will
      not print until {\tt p1} posts (and prints ``Thread 1'') first.
  \end{itemize}~\\[1em]



\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{{\tt volatile} Keyword}


  \begin{itemize}
    \item Used to notify the compiler that the variable may be changed by ``external forces''. For instance,
    %% \item Prevents the compiler from substituting values instead of evaluating
    %%   the value (with proper locking you'll never need this, why?)
  \end{itemize}

  \begin{lstlisting}
int i = 0;

while (i != 255) {
  ...
  \end{lstlisting}

{\tt volatile} prevents this from being optimized to:

  \begin{lstlisting}
int i = 0;

while (true) {
  ...
  \end{lstlisting}

  \begin{itemize}
    \item Variable will not actually be {\tt volatile} in the critical section
      and only prevents useful optimizations.
    \item Usually wrong unless there is a {\bf very} good reason for it.
  \end{itemize}


\end{frame}


\end{document}

