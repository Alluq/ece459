\include{header}

\begin{document}

\lecture{14 --- OpenMP Memory Model}{\term}{Patrick Lam}

\section*{OpenMP Memory Model, Its Pitfalls, and How to Mitigate Them}
OpenMP uses a {\bf relaxed-consistency, shared-memory} model. This almost certainly doesn't 
do what you want. Here are its properties:

\begin{itemize}
    \item All threads share a single store called
      \emph{memory}---this store may not actually represent RAM.
    \item Each thread can have its own {\it temporary} view of memory.
    \item A thread's {\it temporary} view of memory is not required to be
      consistent with memory.
\end{itemize}

We'll talk more about memory models later. Now we're going to talk about 
the OpenMP model and why it's a problem.

\paragraph{Memory Model Pitfall.} Consider this code.

  \begin{verbatim}
                    a = b = 0
/* thread 1 */                      /* thread 2 */

atomic(b = 1) // [1]                atomic(a = 1) // [3]
atomic(tmp = a) // [2]              atomic(tmp = b) // [4]
if (tmp == 0) then                  if (tmp == 0) then
    // protected section                // protected section
end if                              end if
  \end{verbatim}

Does this code actually prevent simultaneous execution?
Let's reason about possible states.

  \begin{center}
  \begin{tabular}{r r r r | r r}
    \multicolumn{4}{c|}{Order} & t1 tmp & t2 tmp\\
    \hline
    1 & 2 & 3 & 4 & 0 & 1\\
    1 & 3 & 2 & 4 & 1 & 1\\
    1 & 3 & 4 & 2 & 1 & 1\\
    3 & 4 & 1 & 2 & 1 & 0\\
    3 & 1 & 2 & 4 & 1 & 1\\
    3 & 1 & 4 & 2 & 1 & 1\\
  \end{tabular}
  \end{center}

Looks like it (at least intuitively).

Sorry! With OpenMP's memory model, no guarantees:
the update from one thread may not be seen by the other.

\paragraph{Restoring Sanity with Flush.} We do rely on 
shared memory working ``properly'', but that's expensive.
So OpenMP provides the {\bf flush} directive.

  \begin{center}
    {\tt \#pragma omp }{\bf flush} {\it[(list)]}
  \end{center}

This directive makes the thread's temporary view of memory consistent with main
      memory; it:
\begin{itemize}
    \item enforces an order on the memory operations of the variables.
\end{itemize}

The variables in the list are called the {\it flush-set}. 
If you give no variables, the compiler will determine them for you.

Enforcing an order on the memory operations means:
\begin{itemize}
    \item All read/write operations on the {\it flush-set} which happen
      before the {\bf flush} complete before the flush executes.
    \item All read/write operations on the {\it flush-set} which happen
      after the {\bf flush} complete after the flush executes.
    \item Flushes with overlapping {\it flush-sets} can not be reordered.
\end{itemize}

To show a consistent value for a variable between two threads, OpenMP
must run statements in this order:

  \begin{enumerate}
    \item $t_1$ writes the value to $v$;
    \item $t_1$ flushes $v$; 
    \item $t_2$ flushes $v$ also;
    \item $t_2$ reads the consistent value from $v$.
  \end{enumerate}

Let's revise the example again.
  \begin{verbatim}
                    a = b = 0
/* thread 1 */                      /* thread 2 */

atomic(b = 1)                       atomic(a = 1)
flush(b)                            flush(a)
flush(a)                            flush(b)
atomic(tmp = a)                     atomic(tmp = b)
if (tmp == 0) then                  if (tmp == 0) then
    // protected section                // protected section
end if                              end if
  \end{verbatim}

OK. Will this now prevent simultaneous access?

Well, no.

The compiler can reorder the {\tt flush(b)} in thread 1 or {\tt
  flush(a)} in thread 2. If {\tt flush(b)} gets reordered to after the
protected section, we will not get our intended operation.

\paragraph{Correct Example.} We have to provide a list of variables
to {\tt flush} to prevent re-ordering:
  \begin{verbatim}
                    a = b = 0
/* thread 1 */                      /* thread 2 */

atomic(b = 1)                       atomic(a = 1)
flush(a, b)                         flush(a, b)
atomic(tmp = a)                     atomic(tmp = b)
if (tmp == 0) then                  if (tmp == 0) then
    // protected section                // protected section
end if                              end if
  \end{verbatim}

\paragraph{Where There's No Implicit Flush:}
  \begin{itemize}
    \item at entry to {\bf for};
    \item at entry to, or exit from, {\bf master};
    \item at entry to {\bf sections};
    \item at entry to {\bf single};
    \item at exit from {\bf for}, {\bf single} or {\bf sections} with a {\bf nowait}
      \begin{itemize}
        \item {\bf nowait} removes implicit flush along with the implicit barrier
      \end{itemize}
  \end{itemize}

This is not true for OpenMP versions before 2.5, so be careful.

\paragraph{Final thoughts on flush.} We've seen that it's very difficult to use flush properly. Really, you should be using mutexes or other synchronization instead of flush~\cite{flush}, because you'll probably just get it wrong. But now you know what flush means.

\section*{OpenMP Task Directive}

  \begin{center}
    {\tt \#pragma omp }{\bf task} {\it [clause [[,] clause]*]}
  \end{center}~\\

Generates a task for a thread in the team to run.
     When a thread enters the region it may:
\begin{itemize}
        \item immediately execute the task; or
        \item defer its execution. (any other thread may be assigned the task)
\end{itemize}

  Allowed Clauses: {\bf if, final, untied, default, mergeable, private,
  firstprivate, shared}

\paragraph{{\tt if} and {\tt final} Clauses.}

  \begin{center}
  {\bf if} {\it(scalar-logical-expression)}
  \end{center}

    When expression is {\tt false}, generates an undeferred task---\\
    the generating task region is suspended until execution of the
      undeferred task finishes.\\[1em]

  \begin{center}
  {\bf final} {\it(scalar-logical-expression)}
  \end{center}

    When expression is {\tt true}, generates a final task.\\
    All tasks within a final task are {\it included}.\\
    Included tasks are undeferred and also execute immediately in the same thread.

Let's look at some examples of these clauses.
  \begin{verbatim}
void foo () {
    int i;
    #pragma omp task if(0) // This task is undeferred
    {
        #pragma omp task
        // This task is a regular task
        for (i = 0; i < 3; i++) {
            #pragma omp task
            // This task is a regular task
            bar();
        }
    }
    #pragma omp task final(1) // This task is a regular task
    {
        #pragma omp task // This task is included
        for (i = 0; i < 3; i++) {
            #pragma omp task
            // This task is also included
            bar();
        }
    }
}
  \end{verbatim}

\paragraph{{\tt untied} and {\tt mergeable} Clauses.}

\begin{center}
  {\bf untied}
\end{center}
  \begin{itemize}
    \item A suspended task can be resumed by any thread.
    \item ``untied'' is ignored if used with {\bf final}.
    \item Interacts poorly with thread-private variables and {\tt gettid()}.
  \end{itemize}

\begin{center}
  {\bf mergeable}
\end{center}

  \begin{itemize}
    \item For an undeferred or included task,
    allows the implementation to generate a merged task instead.
    \item In a merged task, the implementation may re-use the environment from its generating task (as if there was no task directive).
  \end{itemize}

  For more: \url{docs.oracle.com/cd/E24457_01/html/E21996/gljyr.html}

\paragraph{Bad {\tt mergeable} Example.}

  \begin{verbatim}
#include <stdio.h>
void foo () {
    int x = 2;
    #pragma omp task mergeable
    {
        x++; // x is by default firstprivate
    }
    #pragma omp taskwait
    printf("%d\n",x); // prints 2 or 3
}
  \end{verbatim}
  
    This is an incorrect usage of {\bf mergeable}: the output depends
      on whether or not the task got merged.
    Merging tasks (when safe) produces more efficient code.

\paragraph{Taskyield.}

  \begin{center}
    {\tt \#pragma omp }{\bf taskyield}
  \end{center}

This directive specifies that the current task can be suspended in favour of another task.

  Here's a good use of {\bf taskyield}.

  \begin{verbatim}
void foo (omp_lock_t * lock, int n) {
    int i;
    for ( i = 0; i < n; i++ )
    #pragma omp task
    {
        something_useful();
        while (!omp_test_lock(lock)) {
            #pragma omp taskyield
        }
        something_critical();
        omp_unset_lock(lock);
    }
}
  \end{verbatim}

\paragraph{Taskwait.}
  \begin{center}
    {\tt \#pragma omp }{\bf taskwait}
  \end{center}~\\[1em]

     Waits for the completeion of the current task's child tasks.

\section*{OpenMP Examples}
We are next going to look at a sequence of examples showing
how to use OpenMP.

\paragraph{Tree Traversal.}
  \begin{verbatim}
struct node {
    struct node *left;
    struct node *right;
};
extern void process(struct node *);

void traverse(struct node *p) {
    if (p->left)
        #pragma omp task
        // p is firstprivate by default
        traverse(p->left);
    if (p->right)
        #pragma omp task
        // p is firstprivate by default
        traverse(p->right);
    process(p);
}    
  \end{verbatim}

If we want to guarantee a post-order traversal,
we simply need to insert an explicit \verb+#pragma omp taskwait+
after the two calls to {\tt traverse} and before the
call to {\tt process}.


\paragraph{Parallel Linked List Processing.} We can spawn 
tasks to process linked list entries. It's hard to
use two threads to traverse the list, though.

  \begin{verbatim}
// node struct with data and pointer to next
extern void process(node* p);

void increment_list_items(node* head) {
    #pragma omp parallel
    {
        #pragma omp single
        {
            node * p = head;
            while (p) {
                #pragma omp task
                {
                    process(p);
                }
                p = p->next;
            }
        }
    }
}
  \end{verbatim}

\paragraph{Using Lots of Tasks.} Let's see what happens
if we spawn lots of tasks in a {\tt single} directive.

  \begin{verbatim}
#define LARGE_NUMBER 10000000
double item[LARGE_NUMBER];
extern void process(double);

int main() {
    #pragma omp parallel
    {
        #pragma omp single
        {
            int i;
            for (i=0; i<LARGE_NUMBER; i++)
                #pragma omp task
                // i is firstprivate, item is shared
                process(item[i]);
        }
    }
}
  \end{verbatim}

In this case, the main loop generates tasks, which are all assigned to the executing thread as it becomes available (because of {\tt single}).
When too many tasks get generated, OpenMP suspends the main thread, runs some tasks, then resumes the loop in the main thread.

\paragraph{Improved code.} It would be better to {\tt untied} the
spawned tasks, enabling them to run on multiple threads. Surround
the for loop with \verb+#pragma omp task untied+.

\paragraph{About Nesting: Restrictions.}
Let's consider nesting of parallel constructs.
  \begin{itemize}
    \item You cannot nest {\bf for} regions.
    \item You cannot nest {\bf single} inside a {\bf for}.
    \item You cannot nest {\bf barrier} inside a\\~~~~~ {\bf critical/single/master/for}.
  \end{itemize}

Here's something that OpenMP does allow:
  \begin{verbatim}
void good_nesting(int n)
{
    int i, j;
    #pragma omp parallel default(shared)
    {
        #pragma omp for
        for (i=0; i<n; i++) {
            #pragma omp parallel shared(i, n)
            {
                #pragma omp for
                for (j=0; j < n; j++)
                    work(i, j);
            }
        }
    }
}
  \end{verbatim}

\section*{Why Your Code is Slow}
Code too slow? Want it to run faster? Avoid these pitfalls:
  \begin{enumerate}
    \item Unnecessary flush directives.
    \item Using critical sections or locks instead of atomic.
    \item Unnecessary concurrent-memory-writing protection:
      \begin{itemize}
        \item No need to protect local thread variables.
        \item No need to protect if only accessed in {\bf single} or
          {\bf master}.
      \end{itemize}
    \item Too much work in a critical section.
    \item Too many entries into critical sections.
  \end{enumerate}

\paragraph{Example: Too Many Entries into Critical Sections.}

  \begin{verbatim}
#pragma omp parallel for
for (i = 0; i < N; ++i) { 
    #pragma omp critical
    {
        if (arr[i] > max) max = arr[i];
    } 
}
  \end{verbatim}

would be better as:

  \begin{verbatim}
#pragma omp parallel for
for (i = 0 ; i < N; ++i) { 
    #pragma omp flush(max)
    if (arr[i] > max) {
          #pragma omp critical
          {
                if (arr[i] > max) max = arr[i];
          }
    }
}
\end{verbatim}
\input{bibliography.tex}

\end{document}
