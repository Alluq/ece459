\input{configuration}
\usepackage{soul}

\title{Lecture 27 --- Memory Profiling, Cachegrind }

\author{Jeff Zarnett \\ \small \texttt{jzarnett@uwaterloo.ca}}
\institute{Department of Electrical and Computer Engineering \\
  University of Waterloo}
\date{\today}


\begin{document}

\begin{frame}
  \titlepage

 \end{frame}

\part{Memory Profiling}
\begin{frame}
\partpage
\end{frame}

\begin{frame}
\frametitle{\st{Memory Profiling} Return to Asgard}

\large
\begin{changemargin}{2cm}
So far: CPU profiling. 

Memory profiling is also a thing; \\
\qquad specifically heap profiling.

``Still Reachable'': not freed \& still have pointers, \\
\qquad but should have been freed?
\end{changemargin}

\end{frame}



\begin{frame}
\frametitle{\st{Memory Profiling} Return to Asgard}

\large
\begin{changemargin}{2cm}
As with queueing theory:\\
\qquad allocs $>$ frees $\Longrightarrow$ usage $\rightarrow \infty$

At least more paging, maybe total out-of-memory.

But! Memory isn't really lost: we could free it.

Our tool for this comes from the Valgrind tool suite.
\end{changemargin}

\end{frame}


\begin{frame}
\frametitle{Shieldmaiden to Thor}

\begin{center}
	\includegraphics[width=\textwidth]{images/Sif.jpg}
\end{center}

\end{frame}



\begin{frame}
\frametitle{Using Massif}

\Large
\begin{changemargin}{2cm}
What does Massif do? 

\begin{itemize}
\item How much heap memory is your program using?
\item How did this happen?
\end{itemize}

Next up: example from Massif docs.

\end{changemargin}

\end{frame}

\begin{frame}[fragile]
\frametitle{Example Allocation Program}

{\scriptsize
\begin{verbatim}
#include <stdlib.h>

void g ( void ) {
    malloc( 4000 );
}

void f ( void ) {
    malloc( 2000 );
    g();
}

int main ( void ) {
    int i;
    int* a[10];

    for ( i = 0; i < 10; i++ ) {
        a[i] = malloc( 1000 );
    }
    f();
    g();

    for ( i = 0; i < 10; i++ ) {
        free( a[i] );
    }
    return 0;
}
\end{verbatim}
}


\end{frame}

\begin{frame}[fragile]
\frametitle{Send in Sif}

\Large
\begin{changemargin}{2cm}
After we compile (remember \texttt{-g} for debug symbols), run the command:
\end{changemargin}
\vspace*{-4em}
{\scriptsize
\begin{verbatim}
jz@Loki:~/ece459$ valgrind --tool=massif ./massif
==25187== Massif, a heap profiler
==25187== Copyright (C) 2003-2013, and GNU GPL'd, by Nicholas Nethercote
==25187== Using Valgrind-3.10.1 and LibVEX; rerun with -h for copyright info
==25187== Command: ./massif
==25187== 
==25187== 
\end{verbatim}
}

\end{frame}


\begin{frame}
\frametitle{That Was Useful!!!}

\large
\begin{changemargin}{2cm}
What happened? 

\begin{enumerate}
\item The program ran slowly (because Valgrind!)

\item No summary data on the console \\
\hspace*{2em} (like memcheck or helgrind or cachegrind.)
\end{enumerate}

Weird. What we got instead was the file \texttt{massif.out.[PID]}.
\end{changemargin}

\end{frame}


\begin{frame}
\frametitle{Post-Processing}

\Large
\begin{changemargin}{2cm}
\texttt{massif.out.[PID]}:\\
\hspace*{2cm} plain text, sort of readable.

Better: \texttt{ms\_print}.

Which has nothing whatsoever to do with Microsoft. Promise.
\end{changemargin}

\end{frame}


\begin{frame}[fragile]
\frametitle{Post-Processed Output}
{\scriptsize
\begin{verbatim}

    KB
19.71^                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                      :#
     |                                                                      :#
     |                                                                      :#
     |                                                                      :#
   0 +----------------------------------------------------------------------->ki
     0                                                                   111.9
\end{verbatim}
}
\end{frame}


\begin{frame}[fragile]
\frametitle{User Friendly, But Not Useful}

\Large
\begin{changemargin}{2cm}
For a long time, nothing happens, then\ldots kaboom! 

Why? We gave it a trivial program.

We should tell Massif to care more \\
about bytes than CPU cycles,\\
with \verb+--time-unit=B+.

Let's try that.
\end{changemargin}


\end{frame}

\begin{frame}[fragile]
\frametitle{ASCII Art ( \texttt{telnet towel.blinkenlights.nl} )}

{\scriptsize
\begin{verbatim}

    KB
19.71^                                               ### <- peak                
     |                                               #                        
     |                                               #  ::                    
     |                                               #  : ::: <- normal         
     |                                      :::::::::#  : :  ::               
     |                                      :        #  : :  : ::             
     |                                      :        #  : :  : : :::          
     |                                      :        #  : :  : : :  ::        
     |               detailed     :::::::::::        #  : :  : : :  : :::     
     |                     |      :         :        #  : :  : : :  : :  ::   
     |                     v  :::::         :        #  : :  : : :  : :  : :: 
     |                     @@@:   :         :        #  : :  : : :  : :  : : @
     |                   ::@  :   :         :        #  : :  : : :  : :  : : @
     |                :::: @  :   :         :        #  : :  : : :  : :  : : @
     |              :::  : @  :   :         :        #  : :  : : :  : :  : : @
     |            ::: :  : @  :   :         :        #  : :  : : :  : :  : : @
     |         :::: : :  : @  :   :         :        #  : :  : : :  : :  : : @
     |       :::  : : :  : @  :   :         :        #  : :  : : :  : :  : : @
     |    :::: :  : : :  : @  :   :         :        #  : :  : : :  : :  : : @
     |  :::  : :  : : :  : @  :   :         :        #  : :  : : :  : :  : : @
   0 +----------------------------------------------------------------------->KB
     0                                                                   29.63

\end{verbatim}
}

\end{frame}



\begin{frame}
\frametitle{Analyze the Art}

\Large
\begin{changemargin}{2cm}
OK! Massif took 25 snapshots.

\begin{itemize}
\item whenever there are appropriate allocation and deallocation statements, up to a configurable maximum. 
\end{itemize}

Long running program:\\ will toss some old data if necessary. 
\end{changemargin}
\end{frame}



%% \begin{frame}
%% \frametitle{Decode the Symbols}

%% \begin{itemize}
%% \item Normal: :

%% \item Detailed: @

%% \item Peak: \#
%% \end{itemize}

%% Peaks can be slightly inaccurate as they are recorded only at deallocation (and to speed up operations in general).

%% \end{frame}



\begin{frame}[fragile]
\frametitle{Normal Snapshots}

{\scriptsize
\begin{verbatim}
--------------------------------------------------------------------------------
  n        time(B)         total(B)   useful-heap(B) extra-heap(B)    stacks(B)
--------------------------------------------------------------------------------
  0              0                0                0             0            0
  1          1,016            1,016            1,000            16            0
  2          2,032            2,032            2,000            32            0
  3          3,048            3,048            3,000            48            0
  4          4,064            4,064            4,000            64            0
  5          5,080            5,080            5,000            80            0
  6          6,096            6,096            6,000            96            0
  7          7,112            7,112            7,000           112            0
  8          8,128            8,128            8,000           128            0
\end{verbatim}
}

\large
\begin{changemargin}{2cm}
time(B) column = time measured in allocations\\
(our choice of time unit on cmdline).

extra-heap(B) = internal fragmentation.

(Why are stacks all shown as 0?)
\end{changemargin}

\end{frame}


\begin{frame}[fragile]
\frametitle{Detailed Snapshots}

{\scriptsize
\begin{verbatim}
--------------------------------------------------------------------------------
  n        time(B)         total(B)   useful-heap(B) extra-heap(B)    stacks(B)
--------------------------------------------------------------------------------
  9          9,144            9,144            9,000           144            0
98.43% (9,000B) (heap allocation functions) malloc/new/new[], --alloc-fns, etc.
->98.43% (9,000B) 0x4005BB: main (massif.c:17)
\end{verbatim}
}

\large
\begin{changemargin}{2cm}
Now: where did heap allocations take place?

So far, all the allocations took place on line 17,\\
 which was \texttt{  a[i] = malloc( 1000 ); } \\
inside that for loop.
\end{changemargin}

\end{frame}


\begin{frame}[fragile]
\frametitle{Peak Snapshot (Trimmed)}


{\scriptsize
\begin{verbatim}
--------------------------------------------------------------------------------
  n        time(B)         total(B)   useful-heap(B) extra-heap(B)    stacks(B)
--------------------------------------------------------------------------------
 14         20,184           20,184           20,000           184            0
99.09% (20,000B) (heap allocation functions) malloc/new/new[], --alloc-fns, etc.
->49.54% (10,000B) 0x4005BB: main (massif.c:17)
| 
->39.64% (8,000B) 0x400589: g (massif.c:4)
| ->19.82% (4,000B) 0x40059E: f (massif.c:9)
| | ->19.82% (4,000B) 0x4005D7: main (massif.c:20)
| |   
| ->19.82% (4,000B) 0x4005DC: main (massif.c:22)
|   
->09.91% (2,000B) 0x400599: f (massif.c:8)
  ->09.91% (2,000B) 0x4005D7: main (massif.c:20)

\end{verbatim}
}

\large
\begin{changemargin}{2cm}
Massif found  all  allocations  and \\ distilled them to a tree structure.

We see not just where the \texttt{malloc} call happened, but also how we got there.
\end{changemargin}

\end{frame}


\begin{frame}[fragile]
\frametitle{``Is he dead?'' ``Terminated.''}

\large
\begin{changemargin}{2cm}
Termination gives a final output of what blocks remains allocated and where they come from. 

These point to memory leaks, incidentally, and Memcheck would not be amused.
\end{changemargin}
{\scriptsize
\begin{verbatim}
 24         30,344           10,024           10,000            24            0
99.76% (10,000B) (heap allocation functions) malloc/new/new[], --alloc-fns, etc.
->79.81% (8,000B) 0x400589: g (massif.c:4)
| ->39.90% (4,000B) 0x40059E: f (massif.c:9)
| | ->39.90% (4,000B) 0x4005D7: main (massif.c:20)
| |   
| ->39.90% (4,000B) 0x4005DC: main (massif.c:22)
|   
->19.95% (2,000B) 0x400599: f (massif.c:8)
| ->19.95% (2,000B) 0x4005D7: main (massif.c:20)
|   
->00.00% (0B) in 1+ places, all below ms_print's threshold (01.00%)
\end{verbatim}
}


\end{frame}


\begin{frame}[fragile]
\frametitle{Trust, but Verify}

\large
\begin{changemargin}{2cm}
Here's what Memcheck thinks:
\end{changemargin}

{\scriptsize
\begin{verbatim}
jz@Loki:~/ece459$ valgrind ./massif
==25775== Memcheck, a memory error detector
==25775== Copyright (C) 2002-2013, and GNU GPL'd, by Julian Seward et al.
==25775== Using Valgrind-3.10.1 and LibVEX; rerun with -h for copyright info
==25775== Command: ./massif
==25775== 
==25775== 
==25775== HEAP SUMMARY:
==25775==     in use at exit: 10,000 bytes in 3 blocks
==25775==   total heap usage: 13 allocs, 10 frees, 20,000 bytes allocated
==25775== 
==25775== LEAK SUMMARY:
==25775==    definitely lost: 10,000 bytes in 3 blocks
==25775==    indirectly lost: 0 bytes in 0 blocks
==25775==      possibly lost: 0 bytes in 0 blocks
==25775==    still reachable: 0 bytes in 0 blocks
==25775==         suppressed: 0 bytes in 0 blocks
==25775== Rerun with --leak-check=full to see details of leaked memory
==25775== 
==25775== For counts of detected and suppressed errors, rerun with: -v
==25775== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
\end{verbatim}
}


\end{frame}


\begin{frame}
\frametitle{Valgrind (Memcheck) First}

\large
\begin{changemargin}{2cm}
Run valgrind (Memcheck) first and make it happy \\
before we go into figuring out where heap blocks are going with Massif. 

Okay, what to do with the information from Massif, anyway? 

Easy!
\begin{itemize}
\item Start with peak (worst case scenario) \\ and see where that takes you (if anywhere). 

\item You can probably identify some cases where memory is hanging around unnecessarily. 
\end{itemize}
\end{changemargin}


\end{frame}


\begin{frame}
\frametitle{Places to Look with Massif}

\large
\begin{changemargin}{2cm}
Memory usage climbing over a long period of time, perhaps slowly, but never decreasing---memory filling with junk? 

Large spikes in the graph---why so much allocation and deallocation in a short period?
\end{changemargin}
\end{frame}



\begin{frame}[fragile]
\frametitle{Other Massif-ly Useful Things}

\large
\begin{changemargin}{2cm}
\begin{itemize}
	\item stack allocation (\verb+--stacks=yes+).
	\item children of a process \\ (anything split off with \texttt{fork}) if desired.
	\item low level stuff: if going beyond \texttt{malloc}, \texttt{calloc}, \texttt{new}, etc. and using \texttt{mmap} or \texttt{brk} that is usually missed, can do profiling at page level (\verb+--pages-as-heap=yes+).
\end{itemize}
\end{changemargin}

\end{frame}




\begin{frame}
\frametitle{Live Demos}

\large
\begin{changemargin}{2cm}
As is often the case, \\ we have examined the tool on a trivial program. 

Let's see if we can do some\\
 live demos of Massif at work.
\end{changemargin}
\end{frame}

\part{Cachegrind}
\begin{frame}
\partpage
\end{frame}


\begin{frame}
\frametitle{How Would You Know the Difference...}

\begin{center}
	\includegraphics[width=0.5\textwidth]{images/redbluepill.jpg}
\end{center}

This is much more performance oriented than the other two tools. 

 It runs a simulation of how your program interacts with cache and evaluates how your program does on branch prediction.
 

\end{frame}


\begin{frame}
\frametitle{Cachegrind}


 As we discussed earlier, cache misses and branch mispredicts have a huge impact on performance.
 
 Recall that a miss from the fastest cache results in a small penalty (10 cycles).
 
 A miss that requires going to memory requires about 200 cycles. 
 
 A mispredicted branch costs somewhere between 10-30 cycles.


\end{frame}

\begin{frame}
\frametitle{Cachegrind Reporting}

Cachegrind reports data about:
\begin{itemize}
	\item The First Level Instruction Cache (I1) [L1 Instruction Cache]
	\item The First Level Data Cache (D1) [L1 Data Cache]
	\item The Last Level Cache (LL) [L3 Cache].
\end{itemize}

Unlike normal Valgrind operation, you probably want to turn optimizations on.

\end{frame}

\begin{frame}[fragile]
\frametitle{Sim-u-laaaaate!}
{\scriptsize

\begin{verbatim}
jz@Loki:~/ece254$ valgrind --tool=cachegrind --branch-sim=yes ./search

--16559-- warning: L3 cache found, using its data for the LL simulation.
Found at 11 by thread 1 
Found at 22 by thread 3 
==16559== 
==16559== I   refs:      310,670
==16559== I1  misses:      1,700
==16559== LLi misses:      1,292
==16559== I1  miss rate:    0.54%
==16559== LLi miss rate:    0.41%
==16559== 
==16559== D   refs:      114,078  (77,789 rd   + 36,289 wr)
==16559== D1  misses:      4,398  ( 3,360 rd   +  1,038 wr)
==16559== LLd misses:      3,252  ( 2,337 rd   +    915 wr)
==16559== D1  miss rate:     3.8% (   4.3%     +    2.8%  )
==16559== LLd miss rate:     2.8% (   3.0%     +    2.5%  )
==16559== 
==16559== LL refs:         6,098  ( 5,060 rd   +  1,038 wr)
==16559== LL misses:       4,544  ( 3,629 rd   +    915 wr)
==16559== LL miss rate:      1.0% (   0.9%     +    2.5%  )
==16559== 
==16559== Branches:       66,622  (65,097 cond +  1,525 ind)
==16559== Mispredicts:     7,202  ( 6,699 cond +    503 ind)
==16559== Mispred rate:     10.8% (  10.2%     +   32.9%   )

\end{verbatim}
}

\end{frame}

\begin{frame}[fragile]
\frametitle{Optimizations: Enabled!}
{\scriptsize
\begin{verbatim}
jz@Loki:~/ece254$ valgrind --tool=cachegrind --branch-sim=yes ./search

--16618-- warning: L3 cache found, using its data for the LL simulation.
Found at 11 by thread 1 
Found at 22 by thread 3 
==16618== 
==16618== I   refs:      306,169
==16618== I1  misses:      1,652
==16618== LLi misses:      1,286
==16618== I1  miss rate:    0.53%
==16618== LLi miss rate:    0.42%
==16618== 
==16618== D   refs:      112,015  (76,522 rd   + 35,493 wr)
==16618== D1  misses:      4,328  ( 3,353 rd   +    975 wr)
==16618== LLd misses:      3,201  ( 2,337 rd   +    864 wr)
==16618== D1  miss rate:     3.8% (   4.3%     +    2.7%  )
==16618== LLd miss rate:     2.8% (   3.0%     +    2.4%  )
==16618== 
==16618== LL refs:         5,980  ( 5,005 rd   +    975 wr)
==16618== LL misses:       4,487  ( 3,623 rd   +    864 wr)
==16618== LL miss rate:      1.0% (   0.9%     +    2.4%  )
==16618== 
==16618== Branches:       65,827  (64,352 cond +  1,475 ind)
==16618== Mispredicts:     7,109  ( 6,596 cond +    513 ind)
==16618== Mispred rate:     10.7% (  10.2%     +   34.7%   )
\end{verbatim}
}

\end{frame}

\begin{frame}
\frametitle{Results Analysis}


Interesting results: our data and instruction miss rates went down marginally but the branch mispredict rates went up!

Well sort of - there were fewer branches and thus fewer we got wrong as well as fewer we got right. 

So the total cycles lost to mispredicts went down. 

Is this an overall win for the code? Yes. 


\end{frame}
\begin{frame}
\frametitle{Do the Math}

In some cases it's not so clear cut, and we could do a small calculation. 

If we just take a look at the LL misses (4~544 vs 4~487) and assume they take 200 cycles, and the branch miss penalty is 200 cycles, it went from 908~800 wasted cycles to 897~400. This is a decrease of 11~400 cycles.

  Repeat for each of the measures and sum them up to determine if things got better overall and by how much.

\end{frame}
\begin{frame}
\frametitle{Cachegrind Detailed Output}

Cachegrind also produces a more detailed output file, titled cachegrind.out.<pid> (the PID in the example is 16618). 

This file is not especially human-readable, but we can ask the associated tool \texttt{cg\_annotate} to break it down for us.

The output is way too big for slides.

\end{frame}
\begin{frame}
\frametitle{Advanced Cachegrind}

Cachegrind is very... verbose... and it can be very hard to come up with useful changes based on what you see... 

Assuming your eyes don't glaze over when you see the numbers. 

Probably the biggest performance impact is last level cache misses (those appear as DLmr or DLmw). 

You might also try to look at the Bcm and Bim (branch mispredictions) to see if you can give some better hints. 
\end{frame}
\begin{frame}
\frametitle{Really Advanced Cachegrind}

Of course, to learn more about how Cachegrind, the manual is worth reading. 

Not that anybody reads manuals anymore... 

Just give it a shot, when you get stuck, google the problem, click the first stack overflow link result...


\end{frame}


\end{document}

