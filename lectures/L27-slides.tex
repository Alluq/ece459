\input{configuration}
\usepackage{soul}

\title{Lecture 27 --- Memory Profiling, Profiler Guided Optimization }

\author{Jeff Zarnett \\ \small \texttt{jzarnett@uwaterloo.ca}}
\institute{Department of Electrical and Computer Engineering \\
  University of Waterloo}
\date{\today}


\begin{document}

\begin{frame}
  \titlepage

 \end{frame}

\part{Memory Profiling}
\begin{frame}
\partpage
\end{frame}

\begin{frame}
\frametitle{\st{Memory Profiling} Return to Asgard}

\large
\begin{changemargin}{2cm}
So far: CPU profiling. 

Memory profiling is also a thing; \\
\qquad specifically heap profiling.

``Still Reachable'': not freed \& still have pointers, \\
\qquad but should have been freed?
\end{changemargin}

\end{frame}



\begin{frame}
\frametitle{\st{Memory Profiling} Return to Asgard}

\large
\begin{changemargin}{2cm}
As with queueing theory:\\
\qquad allocs $>$ frees $\Longrightarrow$ usage $\rightarrow \infty$

At least more paging, maybe total out-of-memory.

But! Memory isn't really lost: we could free it.

Our tool for this comes from the Valgrind tool suite.
\end{changemargin}

\end{frame}


\begin{frame}
\frametitle{Shieldmaiden to Thor}

\begin{center}
	\includegraphics[width=\textwidth]{images/Sif.jpg}
\end{center}

\end{frame}



\begin{frame}
\frametitle{Using Massif}

\Large
\begin{changemargin}{2cm}
What does Massif do? 

\begin{itemize}
\item How much heap memory is your program using?
\item How did this happen?
\end{itemize}

Next up: example from Massif docs.

\end{changemargin}

\end{frame}

\begin{frame}[fragile]
\frametitle{Example Allocation Program}

{\scriptsize
\begin{verbatim}
#include <stdlib.h>

void g ( void ) {
    malloc( 4000 );
}

void f ( void ) {
    malloc( 2000 );
    g();
}

int main ( void ) {
    int i;
    int* a[10];

    for ( i = 0; i < 10; i++ ) {
        a[i] = malloc( 1000 );
    }
    f();
    g();

    for ( i = 0; i < 10; i++ ) {
        free( a[i] );
    }
    return 0;
}
\end{verbatim}
}


\end{frame}

\begin{frame}[fragile]
\frametitle{Send in Sif}

\Large
\begin{changemargin}{2cm}
After we compile (remember \texttt{-g} for debug symbols), run the command:
\end{changemargin}
\vspace*{-4em}
{\scriptsize
\begin{verbatim}
jz@Loki:~/ece459$ valgrind --tool=massif ./massif
==25187== Massif, a heap profiler
==25187== Copyright (C) 2003-2013, and GNU GPL'd, by Nicholas Nethercote
==25187== Using Valgrind-3.10.1 and LibVEX; rerun with -h for copyright info
==25187== Command: ./massif
==25187== 
==25187== 
\end{verbatim}
}

\end{frame}


\begin{frame}
\frametitle{That Was Useful!!!}

\large
\begin{changemargin}{2cm}
What happened? 

\begin{enumerate}
\item The program ran slowly (because Valgrind!)

\item No summary data on the console \\
\hspace*{2em} (like memcheck or helgrind or cachegrind.)
\end{enumerate}

Weird. What we got instead was the file \texttt{massif.out.[PID]}.
\end{changemargin}

\end{frame}


\begin{frame}
\frametitle{Post-Processing}

\Large
\begin{changemargin}{2cm}
\texttt{massif.out.[PID]}:\\
\hspace*{2cm} plain text, sort of readable.

Better: \texttt{ms\_print}.

Which has nothing whatsoever to do with Microsoft. Promise.
\end{changemargin}

\end{frame}


\begin{frame}[fragile]
\frametitle{Post-Processed Output}
{\scriptsize
\begin{verbatim}

    KB
19.71^                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                       #
     |                                                                      :#
     |                                                                      :#
     |                                                                      :#
     |                                                                      :#
   0 +----------------------------------------------------------------------->ki
     0                                                                   111.9
\end{verbatim}
}
\end{frame}


\begin{frame}[fragile]
\frametitle{User Friendly, But Not Useful}

\Large
\begin{changemargin}{2cm}
For a long time, nothing happens, then\ldots kaboom! 

Why? We gave it a trivial program.

We should tell Massif to care more \\
about bytes than CPU cycles,\\
with \verb+--time-unit=B+.

Let's try that.
\end{changemargin}


\end{frame}

\begin{frame}[fragile]
\frametitle{ASCII Art ( \texttt{telnet towel.blinkenlights.nl} )}

{\scriptsize
\begin{verbatim}

    KB
19.71^                                               ### <- peak                
     |                                               #                        
     |                                               #  ::                    
     |                                               #  : ::: <- normal         
     |                                      :::::::::#  : :  ::               
     |                                      :        #  : :  : ::             
     |                                      :        #  : :  : : :::          
     |                                      :        #  : :  : : :  ::        
     |               detailed     :::::::::::        #  : :  : : :  : :::     
     |                     |      :         :        #  : :  : : :  : :  ::   
     |                     v  :::::         :        #  : :  : : :  : :  : :: 
     |                     @@@:   :         :        #  : :  : : :  : :  : : @
     |                   ::@  :   :         :        #  : :  : : :  : :  : : @
     |                :::: @  :   :         :        #  : :  : : :  : :  : : @
     |              :::  : @  :   :         :        #  : :  : : :  : :  : : @
     |            ::: :  : @  :   :         :        #  : :  : : :  : :  : : @
     |         :::: : :  : @  :   :         :        #  : :  : : :  : :  : : @
     |       :::  : : :  : @  :   :         :        #  : :  : : :  : :  : : @
     |    :::: :  : : :  : @  :   :         :        #  : :  : : :  : :  : : @
     |  :::  : :  : : :  : @  :   :         :        #  : :  : : :  : :  : : @
   0 +----------------------------------------------------------------------->KB
     0                                                                   29.63

\end{verbatim}
}

\end{frame}



\begin{frame}
\frametitle{Analyze the Art}

\Large
\begin{changemargin}{2cm}
OK! Massif took 25 snapshots.

\begin{itemize}
\item whenever there are appropriate allocation and deallocation statements, up to a configurable maximum. 
\end{itemize}

Long running program:\\ will toss some old data if necessary. 
\end{changemargin}
\end{frame}



%% \begin{frame}
%% \frametitle{Decode the Symbols}

%% \begin{itemize}
%% \item Normal: :

%% \item Detailed: @

%% \item Peak: \#
%% \end{itemize}

%% Peaks can be slightly inaccurate as they are recorded only at deallocation (and to speed up operations in general).

%% \end{frame}



\begin{frame}[fragile]
\frametitle{Normal Snapshots}

{\scriptsize
\begin{verbatim}
--------------------------------------------------------------------------------
  n        time(B)         total(B)   useful-heap(B) extra-heap(B)    stacks(B)
--------------------------------------------------------------------------------
  0              0                0                0             0            0
  1          1,016            1,016            1,000            16            0
  2          2,032            2,032            2,000            32            0
  3          3,048            3,048            3,000            48            0
  4          4,064            4,064            4,000            64            0
  5          5,080            5,080            5,000            80            0
  6          6,096            6,096            6,000            96            0
  7          7,112            7,112            7,000           112            0
  8          8,128            8,128            8,000           128            0
\end{verbatim}
}

\large
\begin{changemargin}{2cm}
time(B) column = time measured in allocations\\
(our choice of time unit on cmdline).

extra-heap(B) = internal fragmentation.

(Why are stacks all shown as 0?)
\end{changemargin}

\end{frame}


\begin{frame}[fragile]
\frametitle{Detailed Snapshots}

{\scriptsize
\begin{verbatim}
--------------------------------------------------------------------------------
  n        time(B)         total(B)   useful-heap(B) extra-heap(B)    stacks(B)
--------------------------------------------------------------------------------
  9          9,144            9,144            9,000           144            0
98.43% (9,000B) (heap allocation functions) malloc/new/new[], --alloc-fns, etc.
->98.43% (9,000B) 0x4005BB: main (massif.c:17)
\end{verbatim}
}

\large
\begin{changemargin}{2cm}
Now: where did heap allocations take place?

So far, all the allocations took place on line 17,\\
 which was \texttt{  a[i] = malloc( 1000 ); } \\
inside that for loop.
\end{changemargin}

\end{frame}


\begin{frame}[fragile]
\frametitle{Peak Snapshot (Trimmed)}


{\scriptsize
\begin{verbatim}
--------------------------------------------------------------------------------
  n        time(B)         total(B)   useful-heap(B) extra-heap(B)    stacks(B)
--------------------------------------------------------------------------------
 14         20,184           20,184           20,000           184            0
99.09% (20,000B) (heap allocation functions) malloc/new/new[], --alloc-fns, etc.
->49.54% (10,000B) 0x4005BB: main (massif.c:17)
| 
->39.64% (8,000B) 0x400589: g (massif.c:4)
| ->19.82% (4,000B) 0x40059E: f (massif.c:9)
| | ->19.82% (4,000B) 0x4005D7: main (massif.c:20)
| |   
| ->19.82% (4,000B) 0x4005DC: main (massif.c:22)
|   
->09.91% (2,000B) 0x400599: f (massif.c:8)
  ->09.91% (2,000B) 0x4005D7: main (massif.c:20)

\end{verbatim}
}

\large
\begin{changemargin}{2cm}
Massif found  all  allocations  and \\ distilled them to a tree structure.

We see not just where the \texttt{malloc} call happened, but also how we got there.
\end{changemargin}

\end{frame}


\begin{frame}[fragile]
\frametitle{``Is he dead?'' ``Terminated.''}

\large
\begin{changemargin}{2cm}
Termination gives a final output of what blocks remains allocated and where they come from. 

These point to memory leaks, incidentally, and Memcheck would not be amused.
\end{changemargin}
{\scriptsize
\begin{verbatim}
 24         30,344           10,024           10,000            24            0
99.76% (10,000B) (heap allocation functions) malloc/new/new[], --alloc-fns, etc.
->79.81% (8,000B) 0x400589: g (massif.c:4)
| ->39.90% (4,000B) 0x40059E: f (massif.c:9)
| | ->39.90% (4,000B) 0x4005D7: main (massif.c:20)
| |   
| ->39.90% (4,000B) 0x4005DC: main (massif.c:22)
|   
->19.95% (2,000B) 0x400599: f (massif.c:8)
| ->19.95% (2,000B) 0x4005D7: main (massif.c:20)
|   
->00.00% (0B) in 1+ places, all below ms_print's threshold (01.00%)
\end{verbatim}
}


\end{frame}


\begin{frame}[fragile]
\frametitle{Trust, but Verify}

\large
\begin{changemargin}{2cm}
Here's what Memcheck thinks:
\end{changemargin}

{\scriptsize
\begin{verbatim}
jz@Loki:~/ece459$ valgrind ./massif
==25775== Memcheck, a memory error detector
==25775== Copyright (C) 2002-2013, and GNU GPL'd, by Julian Seward et al.
==25775== Using Valgrind-3.10.1 and LibVEX; rerun with -h for copyright info
==25775== Command: ./massif
==25775== 
==25775== 
==25775== HEAP SUMMARY:
==25775==     in use at exit: 10,000 bytes in 3 blocks
==25775==   total heap usage: 13 allocs, 10 frees, 20,000 bytes allocated
==25775== 
==25775== LEAK SUMMARY:
==25775==    definitely lost: 10,000 bytes in 3 blocks
==25775==    indirectly lost: 0 bytes in 0 blocks
==25775==      possibly lost: 0 bytes in 0 blocks
==25775==    still reachable: 0 bytes in 0 blocks
==25775==         suppressed: 0 bytes in 0 blocks
==25775== Rerun with --leak-check=full to see details of leaked memory
==25775== 
==25775== For counts of detected and suppressed errors, rerun with: -v
==25775== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
\end{verbatim}
}


\end{frame}


\begin{frame}
\frametitle{Valgrind (Memcheck) First}

\large
\begin{changemargin}{2cm}
Run valgrind (Memcheck) first and make it happy \\
before we go into figuring out where heap blocks are going with Massif. 

Okay, what to do with the information from Massif, anyway? 

Easy!
\begin{itemize}
\item Start with peak (worst case scenario) \\ and see where that takes you (if anywhere). 

\item You can probably identify some cases where memory is hanging around unnecessarily. 
\end{itemize}
\end{changemargin}


\end{frame}


\begin{frame}
\frametitle{Places to Look with Massif}

\large
\begin{changemargin}{2cm}
Memory usage climbing over a long period of time, perhaps slowly, but never decreasing---memory filling with junk? 

Large spikes in the graph---why so much allocation and deallocation in a short period?
\end{changemargin}
\end{frame}



\begin{frame}[fragile]
\frametitle{Other Massif-ly Useful Things}

\large
\begin{changemargin}{2cm}
\begin{itemize}
	\item stack allocation (\verb+--stacks=yes+).
	\item children of a process \\ (anything split off with \texttt{fork}) if desired.
	\item low level stuff: if going beyond \texttt{malloc}, \texttt{calloc}, \texttt{new}, etc. and using \texttt{mmap} or \texttt{brk} that is usually missed, can do profiling at page level (\verb+--pages-as-heap=yes+).
\end{itemize}
\end{changemargin}

\end{frame}




\begin{frame}
\frametitle{Live Demos}

\large
\begin{changemargin}{2cm}
As is often the case, \\ we have examined the tool on a trivial program. 

Let's see if we can do some\\
 live demos of Massif at work.
\end{changemargin}
\end{frame}

\part{Profiler Guided Optimization}
\begin{frame}
\partpage
\end{frame}

\begin{frame}
\frametitle{Profiler Guided Optimization}

\Large
\begin{changemargin}{2cm}

Using static analysis, \\
the compiler makes its best predictions about runtime behaviour.

Example: branch prediction. 
\end{changemargin}

\end{frame}



\begin{frame}[fragile]
\frametitle{A Branch To Predict}
\begin{changemargin}{1.5cm}
\begin{lstlisting}[language=C,basicstyle=\large]
void whichBranchIsTaken(int a, int b)
{
    if (a < b) {
        puts("a is less than b.");
    } else {
        puts("b is >= a.");
    }
}
\end{lstlisting}
\end{changemargin}
\end{frame}

\begin{frame}[fragile]
\frametitle{A Virtual Call to Devirtualize}

\begin{changemargin}{2cm}
\begin{lstlisting}[language=C,basicstyle=\large]
void devirtualization(int count)
{
    for (int i = 0; i < count; i++)
    {
        (*p) (x, y);
    }
}
\end{lstlisting}
\end{changemargin}
\end{frame}

\begin{frame}[fragile]
\frametitle{A Switch to Predict}
\begin{changemargin}{2cm}
\begin{lstlisting}[language=C,basicstyle=\large]
void switchCaseExpansion(int i)
{
    switch (i)
    {
    case 1:
        puts("I took case 1.");
        break;
    case 2:
        puts("I took case 2.");
        break;
    }
}
\end{lstlisting}
\end{changemargin}
\end{frame}



\begin{frame}
\frametitle{Adapting to an Uncertain World}
\large
\begin{changemargin}{2cm}
How can we know where we go?
\begin{itemize}
\item could provide hints\ldots
\end{itemize}

Java HotSpot virtual machine: \\
updates predictions on the fly. 

So, just guess.\\
If wrong, the Just-in-Time compiler adjusts \& recompiles.

The compiler runs and it does its job and that's it; the program is never updated with newer predictions if more data becomes known.
\end{changemargin}

\end{frame}



\begin{frame}
\frametitle{Profiling Mitigates Uncertainty}

\large
\begin{changemargin}{2cm}
C: usually no adaptive runtime system.

POGO:
\begin{itemize}
\item observe actual runs;
\item predict the future.
\end{itemize}

So, we need multi-step compilation:
\begin{itemize}
\item compile with profiling;
\item run to collect data;
\item recompile with profiling data to optimize.
\end{itemize}

\end{changemargin}

\end{frame}



\begin{frame}
\frametitle{Step One: Measure}

\large
\begin{changemargin}{2cm}
First, generate an executable with instrumentation. 

The compiler inserts a bunch of probes into the generated code to record data. 
\begin{itemize}
\item Function entry probes;
\item Edge probes;
\item Value probes.
\end{itemize}

Result: instrumented executable \\
plus empty database file (for profiling data).
\end{changemargin}

\end{frame}



\begin{frame}
\frametitle{Step Two: Training Day}

\begin{center}
	\includegraphics[width=0.6\textwidth]{images/training-day.jpg}
\end{center}

\end{frame}


\begin{frame}
\frametitle{Step Two: Training Day}
\large
\begin{changemargin}{2cm}

Second, run the instrumented executable.

Real-world scenarios are best.

Ideally, spend training time on perf-critical sections. 

Use as many runs as you can stand.
\end{changemargin}
\end{frame}



\begin{frame}
\frametitle{Step Two: Training Day}

\large
\begin{changemargin}{2cm}
Don't exercise every part of the program\\
(ain't SE 465 here!)

That would be counterproductive.

Usage data must match real world scenarios,\\
or compiler gets misfacts about what's important. 

Or you might end up teaching it that almost nothing
is important\ldots (``everything's on the exam!'')
\end{changemargin}

\end{frame}



\begin{frame}
\frametitle{Step Three: Recompile}

\large
\begin{changemargin}{2cm}
Finally, compile the program again.

Inputs: source plus training data.

Outputs: (you hope) a better output executable than\\
from static analysis alone.
\end{changemargin}

\end{frame}



\begin{frame}
\frametitle{Summary Graphic}

\begin{center}
	\includegraphics[width=0.75\textwidth]{images/pogo-workflow.jpg}
\end{center}

\end{frame}



\begin{frame}
\frametitle{Save Some Steps}

\large
\begin{changemargin}{2cm}
Not necessary to do all three steps for every build. 

Re-use training data while it's still valid.

Recommended dev workflow:
\begin{itemize}
\item dev A performs these steps, \\
checks the training data into source control
\item whole team can use profiling information for their compiles.
\end{itemize}
\end{changemargin}

\end{frame}



\begin{frame}
\frametitle{Not fixing all the problems in the world}

\large
\begin{changemargin}{2cm}
What does it mean for it to be better? 

The algorithms will aim for \\
speed in areas that are ``hot''. 

The algorithms will aim for \\
minimal code size in areas that are ``cold'' .

Less than 5\% of methods compiled for speed.
\end{changemargin}
\end{frame}



\begin{frame}
\frametitle{Combining Training Runs}

\large
\begin{changemargin}{2cm}
Can combine multiple training runs and manually give suggestions about important scenarios.

The more a scenario runs in the training data, \\
the more important it will be, \\
from POGO's point of view.

Can merge multiple runs \\
with user-assigned weightings.
\end{changemargin}

\end{frame}


\begin{frame}
\frametitle{Behind the Scenes}

\large
\begin{changemargin}{2cm}
In the optimize phase, compiler uses the training data for:

\begin{enumerate}
\item Full and partial inlining
\item Function layout
\item Speed and size decision
\item Basic block layout 
\item Code separation
\item Virtual call speculation
\item Switch expansion
\item Data separation
\item Loop unrolling
\end{enumerate}
\end{changemargin}
\end{frame}



\begin{frame}
\frametitle{Muh Gainz}

\large
\begin{changemargin}{2cm}
Most performance gains from inlining.

Decisions based on the call graph path profiling. 

But: behaviour of function \texttt{foo} may be very different when called from \texttt{B} than when called from \texttt{D}. 


\begin{center}
	\includegraphics[width=0.4\textwidth]{images/callpaths.png}
\end{center}
\end{changemargin}
\end{frame}



\begin{frame}
\frametitle{Another Call Graph}

\large
Example 2 of relationships between functions.\\
Numbers on edges represent the number of invocations:

\begin{center}
	\includegraphics[width=\textwidth]{images/callpaths2.png}
\end{center}

\end{frame}



\begin{frame}
\frametitle{The POGO View of the World}
\large
When considering what to do here, POGO takes the view like this:

\begin{center}
	\includegraphics[width=\textwidth]{images/callpaths3.png}
\end{center}

\end{frame}



\begin{frame}
\frametitle{The POGO View of the World}

\begin{center}
	\includegraphics[width=\textwidth]{images/callpaths4.png}
\end{center}

\end{frame}




\begin{frame}
\frametitle{Page Locality}

\large
\begin{changemargin}{1cm}
Call graph profiling data also good for packing blocks.

Put most common cases nearby.\\
Put successors after their predecessors.

Packing related code = fewer page faults (cache misses).

Calling a function in same page as caller =  ``page locality''.
\end{changemargin}

\end{frame}



\begin{frame}
\frametitle{Block Layout}

\begin{center}
	\includegraphics[width=\textwidth]{images/blocklayout.png}
\end{center}

\end{frame}



\begin{frame}
\frametitle{Dead Code?}

\large
\begin{changemargin}{1cm}
According to the author, ``dead'' code goes in its own special block. 

Probably not truly dead code (compile-time unreachable).

Instead: code that never gets invoked in training.
\end{changemargin}

\end{frame}



\begin{frame}
\frametitle{Benchmark Results}
\large \begin{changemargin}{2cm}
OK, how well does POGO work?

The application under test is a standard benchmark suite (Spec2K):
\end{changemargin}

\begin{center}
\begin{tabular}{l|l|l|l|l|l}
	\textbf{Spec2k:} & \textbf{sjeng} & \textbf{gobmk} & \textbf{perl} & \textbf{povray} & \textbf{gcc}\\ \hline
	\textbf{App Size:} &  {Small} & {Medium} & {Medium} & {Medium} & {Large} \\ \hline
	\textbf{Inlined Edge Count} & 50\% & 53\% & 25\% & 79\% & 65\% \\ \hline
	\textbf{Page Locality} & 97\% & 75\% & 85\% & 98\% & 80\% \\ \hline
	\textbf{Speed Gain} & 8.5\% & 6.6\% & 14.9\% & 36.9\% & 7.9\% \\ 
\end{tabular}
\end{center}

\large \begin{changemargin}{2cm}
We can speculate about how well synthetic benchmarks results translate to real-world application performance\ldots
\end{changemargin}

\end{frame}


\end{document}

