# L20 Self-optimizing software

This lecture is about what software can do on-the-fly to make itself run faster.
The quick summary is:
* caching: easy mode
* observe and change: modify configuration/data layout on the fly
* genetic algorithms: one way of improving configurations/data layouts
* just-in-time compilation/optimization
 + lock optimization
 + on-stack replacement
* binary rewriting

## Observe and change [15 minutes]

Consider the [im docs](https://docs.rs/im/14.3.0/im/):

> For instance, Vec beats everything at memory usage, indexing and operations that happen at the back of the list, but is terrible at insertion and removal, and gets worse the closer to the front of the list you get. VecDeque adds a little bit of complexity in order to make operations at the front as efficient as operations at the back, but is still bad at insertion and especially concatenation. Vector adds another bit of complexity, and could never match Vec at what it's best at, but in return every operation you can throw at it can be completed in a reasonable amount of time - even normally expensive operations like copying and especially concatenation are reasonably cheap when using a Vector.

> It should be noted, however, that because of its simplicity, Vec actually beats Vector even at its strongest operations at small sizes, just because modern CPUs are hyperoptimised for things like copying small chunks of contiguous memory - you actually need to go past a certain size (usually in the vicinity of several hundred elements) before you get to the point where Vec isn't always going to be the fastest choice. Vector attempts to overcome this by actually just being an array at very small sizes, and being able to switch efficiently to the full data structure when it grows large enough. Thus, Vector will actually be equivalent to Vec until it grows past the size of a single chunk.

Exercise: Modify code to decide on the fly which Rust data structure to use.

## Lock optimization simulation [15 minutes]

Maybe we have a program with a bunch of locks and we find locks that
we can optimize based on the workload that we're running the program
with, even though it's not safe in general?

It has to be safe in Rust, but we can coarsen locks and that remains
safe.

## Rewriting the binary [15 minutes]

Have the program modify itself to add inline annotations, recompile
itself and re-invoke the new version of itself.


