\input{configuration}
\usepackage{multirow}

\title{Lecture 10 --- Use of Locks, Reentrancy}

\author{Jeff Zarnett \& Patrick Lam \\ \small \texttt{\{jzarnett, patrick.lam\}@uwaterloo.ca}}
\institute{Department of Electrical and Computer Engineering \\
  University of Waterloo}
\date{\today}


\begin{document}

\begin{frame}
  \titlepage

 \end{frame}


\part{Use of Locks}
\frame{\partpage}


\begin{frame}
\frametitle{Use of Locks}

\vspace*{-3em}
In previous courses: learned about locking and how it works.

Before: was enough to avoid bad stuff.

Now: Still important, but not enough.


\end{frame}


\begin{frame}
\frametitle{Critical Section Size}

  \begin{center}
    \input{images/L07-critsec-size-1}
  \end{center}

\end{frame}

\begin{frame}
\frametitle{Critical Section Size}

  \begin{center}
    \input{images/L07-critsec-size-2}
  \end{center}

Critical sections should be as large as they need to be but no larger. 

\end{frame}


\begin{frame}
\frametitle{Rewrite This Block}

  \begin{center}
    \input{images/L07-critsec-size-3}
  \end{center}

Sometimes control flow or other very short statements might get swept into the critical section.

Those should be the exception rather than the rule.

\end{frame}


\begin{frame}[fragile]
\frametitle{Remember the Producer-Consumer Problem?}

Short code example from the producer-consumer problem:

\begin{lstlisting}[language=C]
sem_t spaces;
sem_t items;
int counter;
int* buffer;
int pindex = 0;
int cindex = 0;
int ctotal = 0;
pthread_mutex_t prod_mutex;
pthread_mutex_t con_mutex;

void consume( int to_consume );

\end{lstlisting}


\end{frame}


\begin{frame}[fragile]
\frametitle{Remember the Producer-Consumer Problem?}

Single-threaded consumer code:

\begin{lstlisting}[language=C]
void* consumer( void* arg ) { 
  while( ctotal < MAX_ITEMS_CONSUMED ) {
    sem_wait( &items );
    consume( buffer[cindex] );
    buffer[cindex] = -1;
    cindex = (cindex + 1) % BUFFER_SIZE;
    ++ctotal;
    sem_post( &spaces );
  }
}
\end{lstlisting}


\end{frame}


\begin{frame}[fragile]
\frametitle{Multiple Consumers}
Must add mutual exclusion to allow multiple simultaneous consumers.

Could allow exactly one consumer to run at a time. We can do better\ldots

\begin{lstlisting}[language=C]
void* consumer( void* arg ) { 
  while( ctotal < MAX_ITEMS_CONSUMED ) {
    pthread_mutex_lock( &con_mutex );
    sem_wait( &items );
    consume( buffer[cindex] );
    buffer[cindex] = -1;
    cindex = (cindex + 1) % BUFFER_SIZE;
    ++ctotal;
    sem_post( &spaces );
    pthread_mutex_unlock( &con_mutex );
  }
}
\end{lstlisting}


\end{frame}


\begin{frame}
\frametitle{Anything to Kick Out?}

\begin{center}
	\includegraphics[width=0.4\textwidth]{images/kickout.png}
\end{center}


\end{frame}



\begin{frame}
\frametitle{Anything to Kick Out?}

At first glance it is probably not very obvious but the \texttt{consume} function takes a regular integer, any old integer, not a pointer of some sort. 

So we could, inside the critical section, read the value of the buffer at the current index into a temp variable. 

That temp variable then can be given to the \texttt{consume} function at any time\ldots outside of the critical section. 

Everything else inside our lock and unlock statements seems to be shared data: operates on \texttt{cindex} or \texttt{ctotal}.


\end{frame}


\begin{frame}[fragile]
\frametitle{Updated Code}

\begin{lstlisting}[language=C]
void* consumer( void* arg ) { 
  while( ctotal < MAX_ITEMS_CONSUMED ) {
    pthread_mutex_lock( &con_mutex );
    sem_wait( &items );
    int temp = buffer[cindex]; // store for now
    buffer[cindex] = -1;
    cindex = (cindex + 1) % BUFFER_SIZE;
    ++ctotal;
    sem_post( &spaces );
    pthread_mutex_unlock( &con_mutex );
    consume( temp ); // consume outside mutex
  }
}
\end{lstlisting}


\end{frame}


\begin{frame}
\frametitle{Did We Get Everything?}

The while condition checks the value of \texttt{ctotal} and that is a read of shared data. 

Now we maybe have a problem. How do we get that inside the critical section?

One idea we might have is to read the value of ctotal into a temporary variable and use that, but it might cause some headaches with the timing\ldots


\end{frame}

\begin{frame}[fragile]
\frametitle{Not Forgetting The Loop Condition}

 Instead what I'd recommend is to make the loop a while true loop and then have a test of the value to determine when we should break out of the loop.
 
 \begin{lstlisting}[language=C]
void* consumer( void* arg ) { 
  while( 1 ) { 
    pthread_mutex_lock( &con_mutex );  
    if ( ctotal == MAX_ITEMS_CONSUMED ) {
      pthread_mutex_unlock( &con_mutex );
      break;
    }   
    sem_wait( &items );
    int temp = buffer[cindex];
    buffer[cindex] = -1; 
    cindex = (cindex + 1) % BUFFER_SIZE;
    ++ctotal;
    pthread_mutex_unlock( &con_mutex );
    sem_post( &spaces );
    consume( temp );
  }
  pthread_exit( NULL );
}
\end{lstlisting}

Are we done?

\end{frame}


\begin{frame}
\frametitle{``Do you think you got him?''}

\begin{center}
	\includegraphics[width=\textwidth]{images/gothim.png}
\end{center}

\end{frame}



\begin{frame}
\frametitle{Locks Have Costs}

Keeping the critical section as small as possible is important because it speeds up performance (reduces the serial portion of your program). 

But that's not the only reason. 

The lock is a resource, and contention for that resource is itself expensive.


\end{frame}


\begin{frame}
\frametitle{Locking Granularity}
Alright, we already know that locks prevent data races.

So we need to use them to prevent data races, but it's not as simple as it sounds. 

We have choices about the granularity of locking, and it is a trade-off.


  \begin{center}
    \includegraphics[scale=0.5]{images/lock-all-the-things}
  \end{center}
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Coarse-Grained Lock}

  \begin{center}
    \input{images/L07-fine-grained-1}
  \end{center}

\end{frame}

\begin{frame}
\frametitle{Fine-Grained Locks}

  \begin{center}
    \input{images/L07-fine-grained-2}
  \end{center}

\end{frame}

\begin{frame}
\frametitle{Coarse-Grained vs Fine-Grained Locking}

\alert{Coarse-grained} locking is easier to write and harder to mess up, but it can significantly reduce opportunities for parallelism. 

\alert{Fine-grained locking} requires more careful design,
increases locking overhead and is more prone to bugs (deadlock etc).  


Locks' extents constitute their granularity. 

\end{frame}


\begin{frame}
\frametitle{Lock Concerns}

We'll discuss three major concerns when using locks:
  \begin{itemize}
    \item overhead;
    \item contention; and
    \item deadlocks.
  \end{itemize}
  
  
We aren't even talking about under-locking (i.e., remaining race conditions).

\end{frame}

\begin{frame}
\frametitle{Lock Overhead}

  Using a lock isn't free. You pay:
  \begin{itemize}
    \item allocated memory for the locks;
    \item initialization and destruction time; and
    \item acquisition and release time.
  \end{itemize}


  These costs scale with the number of locks that you have.
\end{frame}


\begin{frame}
\frametitle{Lock Contention}

\vspace*{-3em}
 Most locking time is wasted waiting for the lock to become available.\\[1em]
We can fix this by:
\vspace*{-3em}
      \begin{itemize}
        \item making the locking regions smaller (more granular); or
        \item making more locks for independent sections.
      \end{itemize}


\end{frame}

\begin{frame}
\frametitle{Deadlocks}

Finally, the more locks you have, the more you have to worry about deadlocks.

\begin{center}
	\includegraphics[width=0.5\textwidth]{images/deadlock.jpg}
\end{center}

As you know, the key condition for a deadlock is waiting for a lock held by process $X$ while holding a lock held by process $X'$. ($X = X'$ is allowed).

\end{frame}


\begin{frame}
\frametitle{Deadlocks}



Okay, in a formal sense, the four conditions for deadlock are:

\begin{enumerate}
	\item \textbf{Mutual Exclusion}
	\item \textbf{Hold-and-Wait}
	\item \textbf{No Preemption}
	\item \textbf{Circular-Wait}
\end{enumerate}

\end{frame}


\begin{frame}[fragile]
\frametitle{Simple Deadlock Example}

Consider, for instance, two processors trying to get two locks.

\begin{center}
  \begin{tabular}{ll}
\begin{minipage}{.4\textwidth}
      {\bf Thread 1}

      \verb+Get Lock 1+

      \verb+Get Lock 2+

      \verb+Release Lock 2+

      \verb+Release Lock 1+
\end{minipage} & 
\begin{minipage}{.4\textwidth}
      {\bf Thread 2}

      \verb+Get Lock 2+

      \verb+Get Lock 1+

      \verb+Release Lock 1+

      \verb+Release Lock 2+
\end{minipage}
\end{tabular}
\end{center}


\end{frame}

\begin{frame}[fragile]
\frametitle{Avoiding Deadlocks}

To avoid deadlocks, always be careful if your code {\bf acquires a lock while holding one}.  
  
You have two choices: (1) ensure consistent ordering in acquiring locks; or (2) use trylock.

As an example of consistent ordering:
\begin{center}
\begin{tabular}{ll}
\begin{minipage}{.4\textwidth}
  \begin{lstlisting}[language=C]
void f1() {
    lock(&l1);
    lock(&l2);
    // protected code
    unlock(&l2);
    unlock(&l1);    
}
\end{lstlisting}
\end{minipage}&
\begin{minipage}{.4\textwidth}
\begin{lstlisting}[language=C]
void f2() {
    lock(&l1);
    lock(&l2);
    // protected code
    unlock(&l2);
    unlock(&l1);    
}
  \end{lstlisting}
\end{minipage}
\end{tabular}
\end{center}

\end{frame}



\begin{frame}[fragile]
\frametitle{Trylock}

Alternately, you can use trylock. 

Recall that Pthreads' {\tt trylock} returns 0 if it gets the lock. 

But if it doesn't, your thread doesn't get blocked. 

\begin{lstlisting}[language=C]
void f1() {
    lock(&l1);
    while (trylock(&l2) != 0) {
        unlock(&l1);
        // wait
        lock(&l1);
    }
    // protected code
    unlock(&l2);
    unlock(&ll);    
}
\end{lstlisting}

This prevents the hold and wait condition.

\end{frame}



\begin{frame}
\frametitle{There Can Be Only One}

\begin{center}
	\includegraphics[width=0.8\textwidth]{images/giantlock.jpg}\\
	\hfill Photo Credit: Craig Middleton\footnote{\url{https://www.flickr.com/photos/craigmiddleton/3579668458}}
\end{center}


\end{frame}


\begin{frame}
\frametitle{Coarse-Grained Locking}

One way of avoiding problems due to locking is to use few locks
(1?). 

This is \emph{coarse-grained locking}; it does have a couple of advantages:
  \begin{itemize}
    \item it is easier to implement;
    \item with one lock, there is no chance of deadlocking; and
    \item it has the lowest memory usage and setup time possible.
  \end{itemize}

Your parallel program will quickly become sequential.


\end{frame}

\begin{frame}
\frametitle{Python}

Python puts a lock around the whole interpreter (known as the
\emph{global interpreter lock}).  

This is the main reason (most) scripting languages have poor parallel performance; Python's just an example.

Two major implications:
\begin{itemize}
\item The only performance benefit you'll see from threading is if one of the threads is
      waiting for I/O.
\item But: any non-I/O-bound threaded program will be {\bf slower} than the sequential
      version (plus, the interpreter will slow down your system).
\end{itemize}


\end{frame}

\begin{frame}
\frametitle{Fine-Grained Locking}

On the other end of the spectrum is \emph{fine-grained locking}. 


\begin{center}
	\includegraphics[width=0.4\textwidth]{images/tinylocks.jpeg}
\end{center}


\end{frame}

\begin{frame}
\frametitle{Fine-Grained Locking} 

The big advantage: it maximizes parallelization in your program.

However, it also comes with a number of disadvantages:
  \begin{itemize}
    \item if your program isn't very parallel, it'll be mostly wasted memory and setup time;
    \item plus, you're now prone to deadlocks; and
    \item fine-grained locking is generally more error-prone (be sure you grab the right lock!)
  \end{itemize}

\end{frame}

\begin{frame}
\frametitle{Lock Scope Examples}


    Databases may lock fields / records / tables. (fine-grained $\rightarrow$ coarse-grained).

    You can also lock individual objects (but beware: sometimes you need transactional guarantees.)



\end{frame}

\part{Reentrancy}
\frame{\partpage}


\begin{frame}
\frametitle{Out and In Again}

\begin{center}
	\includegraphics[width=0.5\textwidth]{images/revolvingdoor.jpg}
\end{center}

\end{frame}


\begin{frame}[fragile]
\frametitle{Non-Reentrant C Function}

The trivial example of a non-reentrant C function:

\begin{lstlisting}[language=C]
int tmp;

void swap( int x, int y ) {
    tmp = y;
    y = x;
    x = tmp;
}
\end{lstlisting}

Why is this non-reentrant?

How can we make it reentrant?

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Reentrancy}

  
    $\Rightarrow$ A function can be suspended in the middle and \\ {\bf re-entered}
      (called again) before the previous execution returns.\\[1em]
    
     Does not always mean {\bf thread-safe} (although it usually is).
      \begin{itemize}
        \item Recall: {\bf thread-safe} is essentially ``no data races''.
      \end{itemize}
 ~\\[1em]
  Moot point if the function only modifies local data, e.g. {\tt sin()}.
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Reentrancy Example}

  

  Courtesy of Wikipedia (with modifications):
  \begin{lstlisting}[language=C]
int t;
 
void swap(int *x, int *y) {
    t = *x;
    *x = *y;
    // hardware interrupt might invoke isr() here!
    *y = t;
}
 
void isr() {
    int x = 1, y = 2;
    swap(&x, &y);
}
...
int a = 3, b = 4;
...
    swap(&a, &b);
  \end{lstlisting}
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Reentrancy Example---Explained (a trace)}

  
  \begin{lstlisting}[language=C]
call swap(&a, &b);
 t = *x;                // t = 3 (a)
 *x = *y;               // a = 4 (b)
 call isr();
    x = 1; y = 2;
    call swap(&x, &y)
    t = *x;             // t = 1 (x)
    *x = *y;            // x = 2 (y)
    *y = t;             // y = 1
 *y = t;                // b = 1

Final values:
a = 4, b = 1

Expected values:
a = 4, b = 3
  \end{lstlisting}
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Reentrancy Example, Fixed}

  
  \begin{lstlisting}[language=C][escapechar=@]
int t;
 
void swap(int *x, int *y) {
    int s;
 
    @\alert{s = t}@;  // save global variable
    t = *x;
    *x = *y;
    // hardware interrupt might invoke isr() here!
    *y = t;
    @\alert{t = s}@;  // restore global variable
}
 
void isr() {
    int x = 1, y = 2;
    swap(&x, &y);
}
...
int a = 3, b = 4;
...
    swap(&a, &b);
  \end{lstlisting}
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Reentrancy Example, Fixed---Explained (a trace)}

  
  \begin{lstlisting}[language=C]
call swap(&a, &b);
s = t;                 // s = UNDEFINED
t = *x;                // t = 3 (a)
*x = *y;               // a = 4 (b)
call isr();
    x = 1; y = 2;
    call swap(&x, &y)
    s = t;             // s = 3
    t = *x;            // t = 1 (x)
    *x = *y;           // x = 2 (y)
    *y = t;            // y = 1
    t = s;             // t = 3
*y = t;                // b = 3
t = s;                 // t = UNDEFINED

Final values:
a = 4, b = 3

Expected values:
a = 4, b = 3
  \end{lstlisting}
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Interrupt Handling}


Remember that in things like interrupt subroutines (ISRs) having the code be reentrant is very important. 

Interrupts can get interrupted by higher priority interrupts and when that happens the ISR may simply be restarted, or we pause and resume.

Either way, if the code is not reentrant we will run into problems.


\end{frame}

\begin{frame}
\frametitle{Thread Safe vs. Reentrant}

Let us also draw a distinction between thread safe code and reentrant code. 

A thread safe operation is one that can be performed from more than one thread at the same time. 

On the other hand, a reentrant operation can be invoked while the operation is already in progress, possibly from within the same thread. 

Or it can be re-started without affecting the outcome. 

If a function is not reentrant, it may not be possible to make it thread safe. 

And furthermore, a reentrant function cannot call a non-reentrant one (and maintain its status as reentrant).

\end{frame}



\begin{frame}[fragile]
\frametitle{Thread Safe Non-Reentrant Example}
{\scriptsize
\begin{lstlisting}[language=C]
int length = 0;
char *s = NULL;

// Note: Since strings end with a 0, if we want to
// add a 0, we encode it as "\0", and encode a
// backslash as "\\".


// WARNING! This code is buggy - do not use!
void AddToString(int ch)
{
  EnterCriticalSection(&someCriticalSection);
  // +1 for the character we're about to add
  // +1 for the null terminator
  char *newString = realloc(s, (length+1) * sizeof(char));
  if (newString) {
    if (ch == '\0' || ch == '\\') {
      AddToString('\\'); // escape prefix
    }
    newString[length++] = ch;
    newString[length] = '\0';
    s = newString;
  }
  LeaveCriticalSection(&someCriticalSection);
}
\end{lstlisting}
}


\end{frame}



\begin{frame}
\frametitle{Analysis of This Example}

Is it thread safe? Sure---there is a critical section protected by the mutex \texttt{someCriticalSection}. 

But is is re-entrant? Nope. 

The internal call to \texttt{AddToString} causes a problem because the attempt to use \texttt{realloc} will use a pointer to \texttt{s}.

That is no longer valid because it got stomped by the earlier call to \texttt{realloc}.


\end{frame}



\begin{frame}
\frametitle{Functional Programming}

Interestingly, functional programming languages (NOT procedural like C) such as Scala and so on, lend themselves very nicely to being parallelized. 

Why? 

Because a purely functional program has no side effects and they are very easy to parallelize.

Any impure function has to indicate that in its function signature.

\end{frame}



\begin{frame}
\frametitle{Functional Programming}

\begin{center}
	\includegraphics[width=0.8\textwidth]{images/functional.png}
\end{center}
{\small \url{https://www.fpcomplete.com/blog/2017/04/pure-functional-programming}}


\end{frame}



\begin{frame}
\frametitle{Joel on Functional}

\begin{quote}
\textit{Without understanding functional programming, you can't invent MapReduce, the algorithm that makes Google so massively scalable. The terms Map and Reduce come from Lisp and functional programming. MapReduce is, in retrospect, obvious to anyone who remembers from their 6.001-equivalent programming class that purely functional programs have no side effects and are thus trivially parallelizable.}
\end{quote}
\hfill --- Joel Spolsky


\end{frame}

\begin{frame}
\frametitle{OOP: \texttt{getBrain().damage()}}

Object oriented programming kind of gives us some bad habits in this regard. 

We tend to make a lot of \texttt{void} methods. 

In functional programming these don't really make sense, because if it's purely functional, then there are some inputs and some outputs. 

If a function returns nothing, what does it do? 

For the most part it can only have side effects which we would generally prefer to avoid if we can, if the goal is to parallelize things. 

\end{frame}

\begin{frame}
\frametitle{Functional Programming in Your C++}

{\tt algorithms} has been part of C++ since C++11.\\

C++17 (not well supported yet) introduces parallel and vectorized {\tt algorithms};\\
\qquad you specify an execution policy, compiler does it:\\
\qquad ({\tt sequenced}, {\tt parallel},
or {\tt parallel\_unsequenced}).\\[1em]

Some examples of algorithms:\\
\qquad {\tt sort}, {\tt reverse}, {\tt is\_heap}\ldots\\[1em]

Other examples of algorithms:\\
\qquad {\tt for\_each\_n}, {\tt exclusive\_scan}, {\tt reduce}\\[1em]
If you know functional programming (e.g. Haskell), these are:\\
\qquad {\tt map}, {\tt scanl}, {\tt fold1/foldl1}.

\end{frame}

\begin{frame}
\frametitle{Side Effects}

Side effects are sort of undesirable (and definitely not functional), but not necessarily bad. 

Printing to console is unavoidably making use of a side effect, but it's what we want. 

We don't want to call print reentrantly, because two threads trying to write at the same time to the console would result in jumbled output. 

Or alternatively, restarting the print routine might result in some doubled characters on the screen.

\end{frame}

\begin{frame}
\frametitle{Purity}

The notion of purity is related to side effects.

A function is \emph{pure} if it has no side effects and if its outputs depend solely on its inputs.

Pure functions should be implemented as thread-safe and reentrant.

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Previous Example: thread-safety}

  
  Is the previous reentrant code also thread-safe?\\

  (This is more what we're concerned about in this course.)\\[1em]

  Let's see:
  \begin{lstlisting}[language=C]
int t;

void swap(int *x, int *y) {
    int s;
 
    s = t;  // save global variable
    t = *x;
    *x = *y;
    // hardware interrupt might invoke isr() here!
    *y = t;
    t = s;  // restore global variable
}
  \end{lstlisting}
  
  Consider two calls: {\tt swap(a, b)}, {\tt swap(c, d)} with\\
  \quad {\tt a = 1, b = 2, c = 3, d = 4}.
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Previous Example: thread-safety trace}

  
  \begin{lstlisting}[language=C]
global: t

/* thread 1 */                       /* thread 2 */
a = 1, b = 2;
s = t;    // s = UNDEFINED
t = a;    // t = 1
                                     c = 3, d = 4;
                                     s = t;    // s = 1
                                     t = c;    // t = 3
                                     c = d;    // c = 4
                                     d = t;    // d = 3
a = b;    // a = 2
b = t;    // b = 3
t = s;    // t = UNDEFINED
                                     t = s;    // t = 1

Final values:
a = 2, b = 3, c = 4, d = 3, t = 1

Expected values:
a = 2, b = 1, c = 4, d = 3, t = UNDEFINED
  \end{lstlisting}
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Reentrancy vs Thread-Safety (1)}

  
  \begin{itemize}
    \item Re-entrant does not always mean thread-safe (as we saw)
      \begin{itemize}
        \item But, for most sane implementations, it is thread-safe
      \end{itemize}
  \end{itemize}~\\[1em]

  Ok, but are {\bf thread-safe} functions reentrant?
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Reentrancy vs Thread-Safety (2)}

  
  Are {\bf thread-safe} functions reentrant? \alert{Nope.} Consider:

  \begin{lstlisting}[language=C]
int f() {
    lock();
    // protected code
    unlock();
}
  \end{lstlisting}

  Recall: {\bf Reentrant functions can be suspended in the middle of execution
    and called again before the previous execution completes.}\\[1em]

  {\tt f()} obviously isn't reentrant. Plus, it will deadlock.\\[1em]

  Interrupt handling is more for systems programming, so the topic of reentrancy may or may not come
  up again.
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Summary of Reentrancy vs Thread-Safety}

  
  Difference between reentrant and thread-safe functions:\\[1em]

  {\bf Reentrancy}
  \begin{itemize}
    \item Has nothing to do with threads---assumes a {\bf single thread}.
    \item Reentrant means the execution can context switch at any point in
      in a function, call the {\bf same function}, and {\bf complete} before
      returning to the original function call.
    \item Function's result does not depend on where the context switch happens.
  \end{itemize}
  \vfill
  {\bf Thread-safety}
  \begin{itemize}
    \item Result does not depend on any interleaving of threads from
      concurrency or parallelism.
    \item No unexpected results from multiple concurrent executions of the function.
  \end{itemize}
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}
  \frametitle{Another Definition of Thread-Safe Functions}

  

\begin{quote}
  ``A function whose effect, when called by two or more threads, is guaranteed to
  be as if the threads each executed the function one after another, in an
  undefined order, even if the actual execution is interleaved.''
\end{quote}
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]
  \frametitle{Past Example of an Exam Question}

  

  \begin{lstlisting}[language=C]
void swap(int *x, int *y) {
    int t;
    t = *x;
    *x = *y;
    *y = t;
}  
  \end{lstlisting}
  \vfill
  \begin{itemize}
    \item Is the above code thread-safe?
    \vfill
    \item Write some expected results for running two calls in parallel.
    \vfill
    \item Argue these expected results always hold, or show an example where
      they do not.
  \end{itemize}
  
\end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%







\end{document}

