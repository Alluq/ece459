\include{header}

\begin{document}

\lecture{15 --- C/C++11 Memory Model}{\term}{Patrick Lam \& Jeff Zarnett}

\section*{C/C++11 Memory Model}

We have talked about memory models in the context of OpenMP. Let's
talk about the core languages now---that is, C and C++~\cite{quora:cppthr, cppconcurrency}---when
not using OpenMP.

What outputs are possible from this example?

\begin{tabular}{ll}
      \begin{minipage}{.2\textwidth}
        Thread 1:
        \begin{lstlisting}[language=C]
  foo = 7;
  bar = 42;
        \end{lstlisting}
      \end{minipage} &
      \begin{minipage}{.4\textwidth}
        Thread 2:
        \begin{lstlisting}[language=C]
  printf("%d\n", foo);
  printf("%d\n", bar);
        \end{lstlisting}
      \end{minipage}
\end{tabular}

You might think ``undefined'', but actually it's worse than that. The 
C11 and C++11 language definitions don't even say what a thread is.
Of course, there is Pthreads, but that is a library, not the language itself.
So you can't even ask this question when talking about pre-C11/C++11 versions
of C and C++. Well. Okay. You can ask, but the question makes no sense. Sort of like
putting your hand up in class and saying ``Where did you bury your oranges?''.
It's a syntactically valid question and it describes something that's possible,
but it still makes no sense.

The older standards made no reference to any kind of CPU, memory architecture, cache
strategy, or anything like that. Which on the one hand is nice and general, but on the other hand, it leads to problems. The ``abstract machine'' that the C and C++ standards refer to is inherently single threaded, making it actually impossible to write a portable multithreaded C or C++ program~\cite{quora:cppthr}. The part that's impossible is that word ``portable'' -- people write multithreaded C and C++ programs all the time (in this class, even) but they have system specific code and implementation-defined behaviour. Open up a pthreads library or some equivalent and sure enough, you will find something architecture specific in there.

C++11 (and C11) have improved the situation, though. There is actually
a memory model (based on an abstract machine) and threading primitives
such as mutexes, atomics, and memory barriers---the concepts that we
have seen in this course. Now there are rules! Yes. We like rules. Okay. I, at least, like rules. C++11 defines how a compiler can generate code that accesses memory even when there is concurrency. There are also standard mutex operations and atomics and barriers and all those lovely things.

Now, we can ask the question about the behaviour of the above example.
It does have undefined behaviour, since there is contended access to
the variables {\tt foo} and {\tt bar}. How can we fix that?

\paragraph{Atomics.}
A good exam question: if {\tt foo} is atomic, what are the possible outputs? 
    
    \begin{tabular}{ll}
      \begin{minipage}{.25\textwidth}
        Thread 1:
        \begin{lstlisting}[language=C]
  foo.store(7);
  bar.store(42);
        \end{lstlisting}
      \end{minipage} &
      \begin{minipage}{.45\textwidth}
        Thread 2:
        \begin{lstlisting}[language=C]
  printf("%d\n", foo.load());
  printf("%d\n", bar.load());
        \end{lstlisting}
      \end{minipage}
    \end{tabular}

Alright, we have some defined behaviour now.  Honestly, it depends how these things are scheduled, but the answer is one of the following set: \{0/0, 7/42, 7/0,  0/42\}. The answer depends on how they are interleaved. But at least we get some certainty that the output will be one of those four things and there's no chance of garbage because the print takes place during an assignment operation. 

We probably still don't like this because we don't have mutual exclusion here and we can get several different answers, some of which are probably ``wrong'' (for whatever definition of a correct answer is), but at least our set of potential wrong answers is smaller. So that's a start. Compilers have to follow the new rules in generating code, so their output will behave as if the architecture followed the standard memory model. That's something. 

\section*{Good C++ Practice}
Lots of people use postfix ({\tt i++}) out of habit, but prefix ({\tt ++i}) is better.

In C, this isn't a problem. 
In some languages (like C++), it can be.

\paragraph{Why? Overloading.} In C++, you can overload the {\tt ++} and {\tt --} operators.

  \begin{lstlisting}[language=C]
class X {
public:
  X& operator++();
  const X operator++(int);
...
};

X x;
++x; // x.operator++();
x++; // x.operator++(0);
  \end{lstlisting}

Prefix is also known as {\bf increment and fetch}, and might be implemented like this:
  \begin{lstlisting}[language=C]
X& X::operator++() {
  *this += 1;
  return *this;
}
  \end{lstlisting}

  Postfix is also known as {\bf fetch and increment}. Note that you have to make a copy of
the old value:
  \begin{lstlisting}[language=C]
const X X::operator++(int) {
  const X old = *this;
  ++(*this);
  return old;
}
  \end{lstlisting}

So, if you're the least concerned about efficiency (and why else would you be
taking programming for performance?), always use
  \emph{prefix} increments/decrements instead of defaulting to postfix. This isn't really an issue if the operator is in a statement all on its own (e.g. a standalone line, or the last part of a for loop) because the compiler is (presumably) smart enough to know that this can be optimized as the return value is not assigned. Only use {\tt postfix} when you really mean it, to be on the safe side.
  
Mind you, if you're doing something like \texttt{array[i++]} or something similarly ``clever'', you might want to think twice about this. There's a lot of potential for error or misunderstanding in a code review. Remember, clever is hard to grep for.


\input{bibliography.tex}

\end{document}
